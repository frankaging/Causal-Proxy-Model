{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating CPM with CEBaB\n",
    "Our Causal Proxy Model (CPM) is for providing concept-based explanation for a blackbox model. We use newly developed CEBaB benchmark for comparing CPM with other concept-based explanation methods. This notebook evaluates CPM with CEBaB benchmark under different settings.\n",
    "\n",
    "More importantly, we introduce new baselines for CPM as well. Formally, we evaluate the blackbox model with interchange intervention evaluation (which will be introduced in details below).\n",
    "\n",
    "In this notebook, we can evaluate the following models:\n",
    "- CPM: `BERT-base-uncased`\n",
    "- CPM: `RoBERTa-base`\n",
    "- CPM: `GPT2`\n",
    "- CPM: `LSTM+GloVe`\n",
    "- CPM: `Control`\n",
    "\n",
    "and we can evaluate with the following conditions:\n",
    "- 2-class\n",
    "- 3-class\n",
    "- 5-class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs import *\n",
    "from modelings.modelings_bert import *\n",
    "from modelings.modelings_roberta import *\n",
    "from modelings.modelings_gpt2 import *\n",
    "from modelings.modelings_lstm import *\n",
    "\"\"\"\n",
    "For evaluate, we use a single random seed, as\n",
    "the models are trained with 5 different seeds\n",
    "already.\n",
    "\"\"\"\n",
    "_ = random.seed(123)\n",
    "_ = np.random.seed(123)\n",
    "_ = torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main evaluate script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "# rerunning the boxes below will only append stuffs to the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The following blocks will run CEBaB benchmark in\n",
    "all the combinations of the following conditions.\n",
    "\"\"\"\n",
    "grid = {\n",
    "    \"eval_split\": [\"dev\"],\n",
    "    # dev,test\n",
    "    \"control\": [\"hdims\"],\n",
    "    # baseline-random,hdims,layers\n",
    "    \"seed\": [42, 66],\n",
    "    # 42, 66, 77\n",
    "    \"h_dim\": [1,16,64,128,192],\n",
    "    # 1,16,64,128,192\n",
    "    # 1,16,64,75\n",
    "    \"interchange_layer\" : [10],\n",
    "    # 0,1; 2,4,6,8,10,12\n",
    "    \"class_num\": [5],\n",
    "    \"k\" : [19684], \n",
    "    # 0,10,100,500,1000,3000,6000,9848,19684\n",
    "    \"alpha\" : [1.0],\n",
    "    # 0.0,1.0\n",
    "    \"beta\" : [1.0],\n",
    "    # 0.0,1.0\n",
    "    \"gemma\" : [3.0],\n",
    "    # 0.0,3.0\n",
    "    \"model_arch\" : [\"bert-base-uncased\"],\n",
    "    # lstm, bert-base-uncased, roberta-base, gpt2\n",
    "    \"lr\" : [\"8e-05\"],\n",
    "    # 8e-05; 0.001\n",
    "    \"counterfactual_type\" : [\"true\"]\n",
    "    # approximate,true\n",
    "}\n",
    "\n",
    "keys, values = zip(*grid.items())\n",
    "permutations_dicts = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "device = 'cuda:9'\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for this setting:  (('eval_split', 'dev'), ('control', 'hdims'), ('seed', 42), ('h_dim', 1), ('interchange_layer', 10), ('class_num', 5), ('k', 19684), ('alpha', 1.0), ('beta', 1.0), ('gemma', 3.0), ('model_arch', 'bert-base-uncased'), ('lr', '8e-05'), ('counterfactual_type', 'true'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration CEBaB--CEBaB-ccd674d249652bd4\n",
      "Reusing dataset parquet (../train_cache/CEBaB___parquet/CEBaB--CEBaB-ccd674d249652bd4/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47692f02b83f4e0fa2a4420eaa916d67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping no majority reviews: 16.6382% of train_exclusive dataset.\n",
      "Dropping no majority reviews: 16.03% of train_inclusive dataset.\n",
      "intervention_h_dim=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/122 [00:00<?, ?it/s]/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/site-packages/transformers/modeling_utils.py:714: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  \"The `device` argument is deprecated and will be removed in v5 of Transformers.\", FutureWarning\n",
      "100%|██████████| 122/122 [00:17<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for this setting:  (('eval_split', 'dev'), ('control', 'hdims'), ('seed', 42), ('h_dim', 16), ('interchange_layer', 10), ('class_num', 5), ('k', 19684), ('alpha', 1.0), ('beta', 1.0), ('gemma', 3.0), ('model_arch', 'bert-base-uncased'), ('lr', '8e-05'), ('counterfactual_type', 'true'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration CEBaB--CEBaB-ccd674d249652bd4\n",
      "Reusing dataset parquet (../train_cache/CEBaB___parquet/CEBaB--CEBaB-ccd674d249652bd4/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e067d2265941df829b7775ee576a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping no majority reviews: 16.6382% of train_exclusive dataset.\n",
      "Dropping no majority reviews: 16.03% of train_inclusive dataset.\n",
      "intervention_h_dim=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:18<00:00,  6.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for this setting:  (('eval_split', 'dev'), ('control', 'hdims'), ('seed', 42), ('h_dim', 64), ('interchange_layer', 10), ('class_num', 5), ('k', 19684), ('alpha', 1.0), ('beta', 1.0), ('gemma', 3.0), ('model_arch', 'bert-base-uncased'), ('lr', '8e-05'), ('counterfactual_type', 'true'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration CEBaB--CEBaB-ccd674d249652bd4\n",
      "Reusing dataset parquet (../train_cache/CEBaB___parquet/CEBaB--CEBaB-ccd674d249652bd4/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3b089280dd419585bfdc66bc11a386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping no majority reviews: 16.6382% of train_exclusive dataset.\n",
      "Dropping no majority reviews: 16.03% of train_inclusive dataset.\n",
      "intervention_h_dim=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:18<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for this setting:  (('eval_split', 'dev'), ('control', 'hdims'), ('seed', 42), ('h_dim', 128), ('interchange_layer', 10), ('class_num', 5), ('k', 19684), ('alpha', 1.0), ('beta', 1.0), ('gemma', 3.0), ('model_arch', 'bert-base-uncased'), ('lr', '8e-05'), ('counterfactual_type', 'true'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration CEBaB--CEBaB-ccd674d249652bd4\n",
      "Reusing dataset parquet (../train_cache/CEBaB___parquet/CEBaB--CEBaB-ccd674d249652bd4/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ad3242e126466db4f4555f75786438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping no majority reviews: 16.6382% of train_exclusive dataset.\n",
      "Dropping no majority reviews: 16.03% of train_inclusive dataset.\n",
      "intervention_h_dim=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:18<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for this setting:  (('eval_split', 'dev'), ('control', 'hdims'), ('seed', 42), ('h_dim', 192), ('interchange_layer', 10), ('class_num', 5), ('k', 19684), ('alpha', 1.0), ('beta', 1.0), ('gemma', 3.0), ('model_arch', 'bert-base-uncased'), ('lr', '8e-05'), ('counterfactual_type', 'true'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration CEBaB--CEBaB-ccd674d249652bd4\n",
      "Reusing dataset parquet (../train_cache/CEBaB___parquet/CEBaB--CEBaB-ccd674d249652bd4/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df43bc98d4404769b030f615ef50d87c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping no majority reviews: 16.6382% of train_exclusive dataset.\n",
      "Dropping no majority reviews: 16.03% of train_inclusive dataset.\n",
      "intervention_h_dim=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:18<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for this setting:  (('eval_split', 'dev'), ('control', 'hdims'), ('seed', 66), ('h_dim', 1), ('interchange_layer', 10), ('class_num', 5), ('k', 19684), ('alpha', 1.0), ('beta', 1.0), ('gemma', 3.0), ('model_arch', 'bert-base-uncased'), ('lr', '8e-05'), ('counterfactual_type', 'true'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration CEBaB--CEBaB-ccd674d249652bd4\n",
      "Reusing dataset parquet (../train_cache/CEBaB___parquet/CEBaB--CEBaB-ccd674d249652bd4/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550c0946667f423cac39d793e22f5a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping no majority reviews: 16.6382% of train_exclusive dataset.\n",
      "Dropping no majority reviews: 16.03% of train_inclusive dataset.\n",
      "intervention_h_dim=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:18<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for this setting:  (('eval_split', 'dev'), ('control', 'hdims'), ('seed', 66), ('h_dim', 16), ('interchange_layer', 10), ('class_num', 5), ('k', 19684), ('alpha', 1.0), ('beta', 1.0), ('gemma', 3.0), ('model_arch', 'bert-base-uncased'), ('lr', '8e-05'), ('counterfactual_type', 'true'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration CEBaB--CEBaB-ccd674d249652bd4\n",
      "Reusing dataset parquet (../train_cache/CEBaB___parquet/CEBaB--CEBaB-ccd674d249652bd4/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916f04e4770a4abfb2eb15494f9d6b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping no majority reviews: 16.6382% of train_exclusive dataset.\n",
      "Dropping no majority reviews: 16.03% of train_inclusive dataset.\n",
      "intervention_h_dim=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:18<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for this setting:  (('eval_split', 'dev'), ('control', 'hdims'), ('seed', 66), ('h_dim', 64), ('interchange_layer', 10), ('class_num', 5), ('k', 19684), ('alpha', 1.0), ('beta', 1.0), ('gemma', 3.0), ('model_arch', 'bert-base-uncased'), ('lr', '8e-05'), ('counterfactual_type', 'true'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration CEBaB--CEBaB-ccd674d249652bd4\n",
      "Reusing dataset parquet (../train_cache/CEBaB___parquet/CEBaB--CEBaB-ccd674d249652bd4/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b19ba8cbda24179ac2f08a6471b66ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping no majority reviews: 16.6382% of train_exclusive dataset.\n",
      "Dropping no majority reviews: 16.03% of train_inclusive dataset.\n",
      "intervention_h_dim=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:18<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for this setting:  (('eval_split', 'dev'), ('control', 'hdims'), ('seed', 66), ('h_dim', 128), ('interchange_layer', 10), ('class_num', 5), ('k', 19684), ('alpha', 1.0), ('beta', 1.0), ('gemma', 3.0), ('model_arch', 'bert-base-uncased'), ('lr', '8e-05'), ('counterfactual_type', 'true'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration CEBaB--CEBaB-ccd674d249652bd4\n",
      "Reusing dataset parquet (../train_cache/CEBaB___parquet/CEBaB--CEBaB-ccd674d249652bd4/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63503b8ead9143c3a64115d60a9ef6e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping no majority reviews: 16.6382% of train_exclusive dataset.\n",
      "Dropping no majority reviews: 16.03% of train_inclusive dataset.\n",
      "intervention_h_dim=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:18<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for this setting:  (('eval_split', 'dev'), ('control', 'hdims'), ('seed', 66), ('h_dim', 192), ('interchange_layer', 10), ('class_num', 5), ('k', 19684), ('alpha', 1.0), ('beta', 1.0), ('gemma', 3.0), ('model_arch', 'bert-base-uncased'), ('lr', '8e-05'), ('counterfactual_type', 'true'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration CEBaB--CEBaB-ccd674d249652bd4\n",
      "Reusing dataset parquet (../train_cache/CEBaB___parquet/CEBaB--CEBaB-ccd674d249652bd4/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f43db9d135ff49e7b592230f95e4a461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping no majority reviews: 16.6382% of train_exclusive dataset.\n",
      "Dropping no majority reviews: 16.03% of train_inclusive dataset.\n",
      "intervention_h_dim=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:18<00:00,  6.74it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(permutations_dicts)):\n",
    "    \n",
    "    eval_split=permutations_dicts[i][\"eval_split\"]\n",
    "    seed=permutations_dicts[i][\"seed\"]\n",
    "    class_num=permutations_dicts[i][\"class_num\"]\n",
    "    alpha=permutations_dicts[i][\"alpha\"]\n",
    "    beta=permutations_dicts[i][\"beta\"]\n",
    "    gemma=permutations_dicts[i][\"gemma\"]\n",
    "    h_dim=permutations_dicts[i][\"h_dim\"]\n",
    "    dataset_type = f'{class_num}-way'\n",
    "    control=permutations_dicts[i][\"control\"]\n",
    "    model_arch=permutations_dicts[i][\"model_arch\"]\n",
    "    k=permutations_dicts[i][\"k\"]\n",
    "    interchange_layer=permutations_dicts[i][\"interchange_layer\"]\n",
    "    lr=permutations_dicts[i][\"lr\"]\n",
    "    counterfactual_type=permutations_dicts[i][\"counterfactual_type\"]\n",
    "    \n",
    "    if model_arch == \"bert-base-uncased\":\n",
    "        model_path = \"BERT\"\n",
    "        model_module = BERTForCEBaB\n",
    "        explainer_module = CausalProxyModelForBERT\n",
    "    elif model_arch == \"roberta-base\":\n",
    "        model_path = \"RoBERTa\" \n",
    "        model_module = RoBERTaForCEBaB\n",
    "        explainer_module = CausalProxyModelForRoBERTa\n",
    "    elif model_arch == \"gpt2\":\n",
    "        model_path = \"gpt2\"\n",
    "        model_module = GPT2ForCEBaB\n",
    "        explainer_module = CausalProxyModelForGPT2\n",
    "    elif model_arch == \"lstm\":\n",
    "        model_path = \"lstm\"\n",
    "        model_module = LSTMForCEBaB\n",
    "        explainer_module = CausalProxyModelForLSTM\n",
    "    model_path += f\"-{control}\"\n",
    "    grid_conditions=(\n",
    "        (\"eval_split\", eval_split),\n",
    "        (\"control\", control),\n",
    "        (\"seed\", seed),\n",
    "        (\"h_dim\", h_dim),\n",
    "        (\"interchange_layer\", interchange_layer),\n",
    "        (\"class_num\", class_num),\n",
    "        (\"k\", k),\n",
    "        (\"alpha\", alpha),\n",
    "        (\"beta\", beta),\n",
    "        (\"gemma\", gemma),\n",
    "        (\"model_arch\", model_arch),\n",
    "        (\"lr\", lr),\n",
    "        (\"counterfactual_type\", counterfactual_type)\n",
    "    )\n",
    "    print(\"Running for this setting: \", grid_conditions)\n",
    "\n",
    "    blackbox_model_path = f'CEBaB/{model_arch}.CEBaB.sa.'\\\n",
    "                          f'{class_num}-class.exclusive.seed_{seed}'\n",
    "    cpm_model_path = f'../proxy_training_results/{model_path}/'\\\n",
    "                     f'cebab.alpha.{alpha}.beta.{beta}.gemma.{gemma}.'\\\n",
    "                     f'lr.{lr}.dim.{h_dim}.hightype.{model_arch}.'\\\n",
    "                     f'CEBaB.cls.dropout.0.1.enc.dropout.0.1.counter.type.'\\\n",
    "                     f'{counterfactual_type}.k.{k}.int.layer.{interchange_layer}.'\\\n",
    "                     f'seed_{seed}/'\n",
    "\n",
    "    # load data from HF\n",
    "    cebab = datasets.load_dataset(\n",
    "        'CEBaB/CEBaB', use_auth_token=True,\n",
    "        cache_dir=\"../train_cache/\"\n",
    "    )\n",
    "\n",
    "    train, dev, test = preprocess_hf_dataset_inclusive(\n",
    "        cebab, verbose=1, dataset_type=dataset_type\n",
    "    )\n",
    "\n",
    "    eval_dataset = dev if eval_split == 'dev' else test\n",
    "\n",
    "    tf_model = model_module(\n",
    "        blackbox_model_path, \n",
    "        device=device, \n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    explainer = explainer_module(\n",
    "        blackbox_model_path,\n",
    "        cpm_model_path, \n",
    "        device=device, \n",
    "        batch_size=batch_size,\n",
    "        intervention_h_dim=h_dim,\n",
    "    )\n",
    "\n",
    "    result_per_example, ATE, CEBaB_metrics, CEBaB_metrics_per_aspect_direction, \\\n",
    "    CEBaB_metrics_per_aspect, CaCE_per_aspect_direction, \\\n",
    "    ACaCE_per_aspect, performance_report = cebab_pipeline(\n",
    "        tf_model, explainer, \n",
    "        train, eval_dataset,\n",
    "        seed, k, dataset_type=dataset_type, \n",
    "        shorten_model_name=False, \n",
    "        train_setting=\"inclusive\", \n",
    "        approximate=False if counterfactual_type == \"true\" else True\n",
    "    )\n",
    "    \n",
    "    results[grid_conditions] = (\n",
    "        result_per_example, ATE, CEBaB_metrics, CEBaB_metrics_per_aspect_direction, \\\n",
    "        CEBaB_metrics_per_aspect, CaCE_per_aspect_direction, \\\n",
    "        ACaCE_per_aspect, performance_report\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_split</th>\n",
       "      <th>control</th>\n",
       "      <th>seed</th>\n",
       "      <th>h_dim</th>\n",
       "      <th>interchange_layer</th>\n",
       "      <th>class_num</th>\n",
       "      <th>k</th>\n",
       "      <th>beta</th>\n",
       "      <th>gemma</th>\n",
       "      <th>model_arch</th>\n",
       "      <th>lr</th>\n",
       "      <th>counterfactual_type</th>\n",
       "      <th>ICaCE-L2</th>\n",
       "      <th>ICaCE-cosine</th>\n",
       "      <th>ICaCE-normdiff</th>\n",
       "      <th>macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>ks-after-bug-fix</td>\n",
       "      <td>42</td>\n",
       "      <td>192</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.6747</td>\n",
       "      <td>0.5709</td>\n",
       "      <td>0.4875</td>\n",
       "      <td>0.500900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>ks-after-bug-fix</td>\n",
       "      <td>42</td>\n",
       "      <td>192</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.6381</td>\n",
       "      <td>0.5432</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>0.565917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>ks-after-bug-fix</td>\n",
       "      <td>42</td>\n",
       "      <td>192</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.6538</td>\n",
       "      <td>0.5509</td>\n",
       "      <td>0.4863</td>\n",
       "      <td>0.502520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>ks-after-bug-fix</td>\n",
       "      <td>42</td>\n",
       "      <td>192</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.6514</td>\n",
       "      <td>0.5446</td>\n",
       "      <td>0.4829</td>\n",
       "      <td>0.533229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>ks-after-bug-fix</td>\n",
       "      <td>42</td>\n",
       "      <td>192</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>3000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.6370</td>\n",
       "      <td>0.5317</td>\n",
       "      <td>0.4732</td>\n",
       "      <td>0.532873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test</td>\n",
       "      <td>ks-after-bug-fix</td>\n",
       "      <td>42</td>\n",
       "      <td>192</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>6000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.4462</td>\n",
       "      <td>0.4076</td>\n",
       "      <td>0.3002</td>\n",
       "      <td>0.655451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test</td>\n",
       "      <td>ks-after-bug-fix</td>\n",
       "      <td>42</td>\n",
       "      <td>192</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>9848</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.4340</td>\n",
       "      <td>0.4026</td>\n",
       "      <td>0.2888</td>\n",
       "      <td>0.665128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test</td>\n",
       "      <td>ks-after-bug-fix</td>\n",
       "      <td>42</td>\n",
       "      <td>192</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>19684</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.4090</td>\n",
       "      <td>0.3625</td>\n",
       "      <td>0.2535</td>\n",
       "      <td>0.676245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  eval_split           control  seed  h_dim  interchange_layer  class_num  \\\n",
       "0       test  ks-after-bug-fix    42    192                 12          5   \n",
       "1       test  ks-after-bug-fix    42    192                 12          5   \n",
       "2       test  ks-after-bug-fix    42    192                 12          5   \n",
       "3       test  ks-after-bug-fix    42    192                 12          5   \n",
       "4       test  ks-after-bug-fix    42    192                 12          5   \n",
       "5       test  ks-after-bug-fix    42    192                 12          5   \n",
       "6       test  ks-after-bug-fix    42    192                 12          5   \n",
       "7       test  ks-after-bug-fix    42    192                 12          5   \n",
       "\n",
       "       k  beta  gemma model_arch     lr counterfactual_type  ICaCE-L2  \\\n",
       "0     10   1.0    3.0       gpt2  8e-05                true    0.6747   \n",
       "1    100   1.0    3.0       gpt2  8e-05                true    0.6381   \n",
       "2    500   1.0    3.0       gpt2  8e-05                true    0.6538   \n",
       "3   1000   1.0    3.0       gpt2  8e-05                true    0.6514   \n",
       "4   3000   1.0    3.0       gpt2  8e-05                true    0.6370   \n",
       "5   6000   1.0    3.0       gpt2  8e-05                true    0.4462   \n",
       "6   9848   1.0    3.0       gpt2  8e-05                true    0.4340   \n",
       "7  19684   1.0    3.0       gpt2  8e-05                true    0.4090   \n",
       "\n",
       "   ICaCE-cosine  ICaCE-normdiff  macro-f1  \n",
       "0        0.5709          0.4875  0.500900  \n",
       "1        0.5432          0.4828  0.565917  \n",
       "2        0.5509          0.4863  0.502520  \n",
       "3        0.5446          0.4829  0.533229  \n",
       "4        0.5317          0.4732  0.532873  \n",
       "5        0.4076          0.3002  0.655451  \n",
       "6        0.4026          0.2888  0.665128  \n",
       "7        0.3625          0.2535  0.676245  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_keys = [\n",
    "    \"eval_split\",\n",
    "    \"control\", \"seed\", \n",
    "    \"h_dim\", \"interchange_layer\", \n",
    "    \"class_num\", \"k\", \n",
    "    \"beta\", \"gemma\", \n",
    "    \"model_arch\", \"lr\", \"counterfactual_type\"\n",
    "]\n",
    "values = []\n",
    "for k, v in results.items():\n",
    "    _values = []\n",
    "    for ik in important_keys:\n",
    "        _values.append(dict(k)[ik])\n",
    "    _values.append(v[2][\"ICaCE-L2\"].iloc[0])\n",
    "    _values.append(v[2][\"ICaCE-cosine\"].iloc[0])\n",
    "    _values.append(v[2][\"ICaCE-normdiff\"].iloc[0])\n",
    "    _values.append(v[-1].iloc[0][0])\n",
    "    values.append(_values)\n",
    "important_keys.extend([\"ICaCE-L2\", \"ICaCE-cosine\", \"ICaCE-normdiff\", \"macro-f1\"])\n",
    "df = pd.DataFrame(values, columns=important_keys)\n",
    "df.sort_values(by=['seed', 'interchange_layer', 'h_dim'], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregating results in the way you like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>seed</th>\n",
       "      <th>h_dim</th>\n",
       "      <th>interchange_layer</th>\n",
       "      <th>class_num</th>\n",
       "      <th>beta</th>\n",
       "      <th>gemma</th>\n",
       "      <th>ICaCE-L2</th>\n",
       "      <th>ICaCE-cosine</th>\n",
       "      <th>ICaCE-normdiff</th>\n",
       "      <th>macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>42.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6747</td>\n",
       "      <td>0.5709</td>\n",
       "      <td>0.4875</td>\n",
       "      <td>0.500900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>42.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6381</td>\n",
       "      <td>0.5432</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>0.565917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>42.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6538</td>\n",
       "      <td>0.5509</td>\n",
       "      <td>0.4863</td>\n",
       "      <td>0.502520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6514</td>\n",
       "      <td>0.5446</td>\n",
       "      <td>0.4829</td>\n",
       "      <td>0.533229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6370</td>\n",
       "      <td>0.5317</td>\n",
       "      <td>0.4732</td>\n",
       "      <td>0.532873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4462</td>\n",
       "      <td>0.4076</td>\n",
       "      <td>0.3002</td>\n",
       "      <td>0.655451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9848</td>\n",
       "      <td>42.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4340</td>\n",
       "      <td>0.4026</td>\n",
       "      <td>0.2888</td>\n",
       "      <td>0.665128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19684</td>\n",
       "      <td>42.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4090</td>\n",
       "      <td>0.3625</td>\n",
       "      <td>0.2535</td>\n",
       "      <td>0.676245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       k  seed  h_dim  interchange_layer  class_num  beta  gemma  ICaCE-L2  \\\n",
       "0     10  42.0  192.0               12.0        5.0   1.0    3.0    0.6747   \n",
       "1    100  42.0  192.0               12.0        5.0   1.0    3.0    0.6381   \n",
       "2    500  42.0  192.0               12.0        5.0   1.0    3.0    0.6538   \n",
       "3   1000  42.0  192.0               12.0        5.0   1.0    3.0    0.6514   \n",
       "4   3000  42.0  192.0               12.0        5.0   1.0    3.0    0.6370   \n",
       "5   6000  42.0  192.0               12.0        5.0   1.0    3.0    0.4462   \n",
       "6   9848  42.0  192.0               12.0        5.0   1.0    3.0    0.4340   \n",
       "7  19684  42.0  192.0               12.0        5.0   1.0    3.0    0.4090   \n",
       "\n",
       "   ICaCE-cosine  ICaCE-normdiff  macro-f1  \n",
       "0        0.5709          0.4875  0.500900  \n",
       "1        0.5432          0.4828  0.565917  \n",
       "2        0.5509          0.4863  0.502520  \n",
       "3        0.5446          0.4829  0.533229  \n",
       "4        0.5317          0.4732  0.532873  \n",
       "5        0.4076          0.3002  0.655451  \n",
       "6        0.4026          0.2888  0.665128  \n",
       "7        0.3625          0.2535  0.676245  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['k'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>seed</th>\n",
       "      <th>h_dim</th>\n",
       "      <th>interchange_layer</th>\n",
       "      <th>class_num</th>\n",
       "      <th>beta</th>\n",
       "      <th>gemma</th>\n",
       "      <th>ICaCE-L2</th>\n",
       "      <th>ICaCE-cosine</th>\n",
       "      <th>ICaCE-normdiff</th>\n",
       "      <th>macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       k  seed  h_dim  interchange_layer  class_num  beta  gemma  ICaCE-L2  \\\n",
       "0     10   NaN    NaN                NaN        NaN   NaN    NaN       NaN   \n",
       "1    100   NaN    NaN                NaN        NaN   NaN    NaN       NaN   \n",
       "2    500   NaN    NaN                NaN        NaN   NaN    NaN       NaN   \n",
       "3   1000   NaN    NaN                NaN        NaN   NaN    NaN       NaN   \n",
       "4   3000   NaN    NaN                NaN        NaN   NaN    NaN       NaN   \n",
       "5   6000   NaN    NaN                NaN        NaN   NaN    NaN       NaN   \n",
       "6   9848   NaN    NaN                NaN        NaN   NaN    NaN       NaN   \n",
       "7  19684   NaN    NaN                NaN        NaN   NaN    NaN       NaN   \n",
       "\n",
       "   ICaCE-cosine  ICaCE-normdiff  macro-f1  \n",
       "0           NaN             NaN       NaN  \n",
       "1           NaN             NaN       NaN  \n",
       "2           NaN             NaN       NaN  \n",
       "3           NaN             NaN       NaN  \n",
       "4           NaN             NaN       NaN  \n",
       "5           NaN             NaN       NaN  \n",
       "6           NaN             NaN       NaN  \n",
       "7           NaN             NaN       NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['k'], as_index=False).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save your results somewhere and load again to tabularize your results altogether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name = input(\"Plase give an output file name: \")\n",
    "\n",
    "output_directory = f'../proxy_training_results/{model_path}/'\n",
    "output_filename = os.path.join(output_directory, f'{output_name}.pkl')\n",
    "print(\"Writing to file: \", output_filename)\n",
    "with open(output_filename, 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

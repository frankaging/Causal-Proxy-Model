{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating CPM with CEBaB\n",
    "Our Causal Proxy Model (CPM) is for providing concept-based explanation for a blackbox model. We use newly developed CEBaB benchmark for comparing CPM with other concept-based explanation methods. This notebook evaluates CPM with CEBaB benchmark under different settings.\n",
    "\n",
    "More importantly, we introduce new baselines for CPM as well. Formally, we evaluate the blackbox model with interchange intervention evaluation (which will be introduced in details below).\n",
    "\n",
    "In this notebook, we can evaluate the following models:\n",
    "- CPM: `BERT-base-uncased`\n",
    "- CPM: `RoBERTa-base`\n",
    "- CPM: `GPT2`\n",
    "- CPM: `LSTM+GloVe`\n",
    "- CPM: `Control`\n",
    "\n",
    "and we can evaluate with the following conditions:\n",
    "- 2-class\n",
    "- 3-class\n",
    "- 5-class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs import *\n",
    "from modelings.modelings_bert import *\n",
    "from modelings.modelings_roberta import *\n",
    "from modelings.modelings_gpt2 import *\n",
    "from modelings.modelings_lstm import *\n",
    "\"\"\"\n",
    "For evaluate, we use a single random seed, as\n",
    "the models are trained with 5 different seeds\n",
    "already.\n",
    "\"\"\"\n",
    "_ = random.seed(123)\n",
    "_ = np.random.seed(123)\n",
    "_ = torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main evaluate script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "# rerunning the boxes below will only append stuffs to the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The following blocks will run CEBaB benchmark in\n",
    "all the combinations of the following conditions.\n",
    "\"\"\"\n",
    "grid = {\n",
    "    \"eval_split\": [\"test\"],\n",
    "    # dev,test\n",
    "    \"control\": [\"approximate\"],\n",
    "    # baseline-random,baseline-blackbox,hdims,layers,ks,approximate,ablation\n",
    "    \"seed\": [42, 66, 77],\n",
    "    # 42, 66, 77\n",
    "    \"h_dim\": [192],\n",
    "    # 1,16,64,128,192\n",
    "    # 1,16,64,75\n",
    "    \"interchange_layer\" : [10],\n",
    "    # 0,1; 2,4,6,8,10,12\n",
    "    \"class_num\": [5],\n",
    "    \"k\" : [0], \n",
    "    # 0,10,100,500,1000,3000,6000,9848,19684\n",
    "    \"alpha\" : [1.0],\n",
    "    # 0.0,1.0\n",
    "    \"beta\" : [1.0],\n",
    "    # 0.0,1.0\n",
    "    \"gemma\" : [3.0],\n",
    "    # 0.0,3.0\n",
    "    \"model_arch\" : [\"bert-base-uncased\"],\n",
    "    # lstm, bert-base-uncased, roberta-base, gpt2\n",
    "    \"lr\" : [\"8e-05\"],\n",
    "    # 8e-05; 0.001\n",
    "    \"counterfactual_type\" : [\"approximate\"]\n",
    "    # approximate,true\n",
    "}\n",
    "\n",
    "keys, values = zip(*grid.items())\n",
    "permutations_dicts = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "device = 'cuda:9'\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for this setting:  (('eval_split', 'test'), ('control', 'approximate'), ('seed', 42), ('h_dim', 192), ('interchange_layer', 10), ('class_num', 5), ('k', 0), ('alpha', 1.0), ('beta', 1.0), ('gemma', 3.0), ('model_arch', 'bert-base-uncased'), ('lr', '8e-05'), ('counterfactual_type', 'approximate'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration CEBaB--CEBaB-ccd674d249652bd4\n",
      "Reusing dataset parquet (../train_cache/CEBaB___parquet/CEBaB--CEBaB-ccd674d249652bd4/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b3b16115764b128010ea4237a1abb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping no majority reviews: 16.6382% of train_exclusive dataset.\n",
      "Dropping no majority reviews: 16.03% of train_inclusive dataset.\n",
      "intervention_h_dim=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../eval_pipeline/utils/data_utils.py:219: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pairs['intervention_type'][pairs[f'{aspect}_aspect_majority_base'] != pairs[f'{aspect}_aspect_majority_counterfactual']] = aspect\n",
      "  0%|          | 0/124 [00:00<?, ?it/s]/dfs/user/wuzhengx/tool-chain/anaconda3/lib/python3.7/site-packages/transformers/modeling_utils.py:714: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  \"The `device` argument is deprecated and will be removed in v5 of Transformers.\", FutureWarning\n",
      "100%|██████████| 124/124 [00:17<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for this setting:  (('eval_split', 'test'), ('control', 'approximate'), ('seed', 66), ('h_dim', 192), ('interchange_layer', 10), ('class_num', 5), ('k', 0), ('alpha', 1.0), ('beta', 1.0), ('gemma', 3.0), ('model_arch', 'bert-base-uncased'), ('lr', '8e-05'), ('counterfactual_type', 'approximate'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration CEBaB--CEBaB-ccd674d249652bd4\n",
      "Reusing dataset parquet (../train_cache/CEBaB___parquet/CEBaB--CEBaB-ccd674d249652bd4/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c0172de9d44649ad24b36f84c2cfc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping no majority reviews: 16.6382% of train_exclusive dataset.\n",
      "Dropping no majority reviews: 16.03% of train_inclusive dataset.\n",
      "intervention_h_dim=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:17<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for this setting:  (('eval_split', 'test'), ('control', 'approximate'), ('seed', 77), ('h_dim', 192), ('interchange_layer', 10), ('class_num', 5), ('k', 0), ('alpha', 1.0), ('beta', 1.0), ('gemma', 3.0), ('model_arch', 'bert-base-uncased'), ('lr', '8e-05'), ('counterfactual_type', 'approximate'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration CEBaB--CEBaB-ccd674d249652bd4\n",
      "Reusing dataset parquet (../train_cache/CEBaB___parquet/CEBaB--CEBaB-ccd674d249652bd4/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06a6cfeb79474781a865284828b868ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping no majority reviews: 16.6382% of train_exclusive dataset.\n",
      "Dropping no majority reviews: 16.03% of train_inclusive dataset.\n",
      "intervention_h_dim=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:17<00:00,  7.25it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(permutations_dicts)):\n",
    "    \n",
    "    eval_split=permutations_dicts[i][\"eval_split\"]\n",
    "    seed=permutations_dicts[i][\"seed\"]\n",
    "    class_num=permutations_dicts[i][\"class_num\"]\n",
    "    alpha=permutations_dicts[i][\"alpha\"]\n",
    "    beta=permutations_dicts[i][\"beta\"]\n",
    "    gemma=permutations_dicts[i][\"gemma\"]\n",
    "    h_dim=permutations_dicts[i][\"h_dim\"]\n",
    "    dataset_type = f'{class_num}-way'\n",
    "    control=permutations_dicts[i][\"control\"]\n",
    "    model_arch=permutations_dicts[i][\"model_arch\"]\n",
    "    k=permutations_dicts[i][\"k\"]\n",
    "    interchange_layer=permutations_dicts[i][\"interchange_layer\"]\n",
    "    lr=permutations_dicts[i][\"lr\"]\n",
    "    counterfactual_type=permutations_dicts[i][\"counterfactual_type\"]\n",
    "    \n",
    "    if model_arch == \"bert-base-uncased\":\n",
    "        model_path = \"BERT\"\n",
    "        model_module = BERTForCEBaB\n",
    "        explainer_module = CausalProxyModelForBERT\n",
    "    elif model_arch == \"roberta-base\":\n",
    "        model_path = \"RoBERTa\" \n",
    "        model_module = RoBERTaForCEBaB\n",
    "        explainer_module = CausalProxyModelForRoBERTa\n",
    "    elif model_arch == \"gpt2\":\n",
    "        model_path = \"gpt2\"\n",
    "        model_module = GPT2ForCEBaB\n",
    "        explainer_module = CausalProxyModelForGPT2\n",
    "    elif model_arch == \"lstm\":\n",
    "        model_path = \"lstm\"\n",
    "        model_module = LSTMForCEBaB\n",
    "        explainer_module = CausalProxyModelForLSTM\n",
    "    model_path += f\"-{control}\"\n",
    "    grid_conditions=(\n",
    "        (\"eval_split\", eval_split),\n",
    "        (\"control\", control),\n",
    "        (\"seed\", seed),\n",
    "        (\"h_dim\", h_dim),\n",
    "        (\"interchange_layer\", interchange_layer),\n",
    "        (\"class_num\", class_num),\n",
    "        (\"k\", k),\n",
    "        (\"alpha\", alpha),\n",
    "        (\"beta\", beta),\n",
    "        (\"gemma\", gemma),\n",
    "        (\"model_arch\", model_arch),\n",
    "        (\"lr\", lr),\n",
    "        (\"counterfactual_type\", counterfactual_type)\n",
    "    )\n",
    "    print(\"Running for this setting: \", grid_conditions)\n",
    "\n",
    "    blackbox_model_path = f'CEBaB/{model_arch}.CEBaB.sa.'\\\n",
    "                          f'{class_num}-class.exclusive.seed_{seed}'\n",
    "    cpm_model_path = f'../proxy_training_results/{model_path}/'\\\n",
    "                     f'cebab.alpha.{alpha}.beta.{beta}.gemma.{gemma}.'\\\n",
    "                     f'lr.{lr}.dim.{h_dim}.hightype.{model_arch}.'\\\n",
    "                     f'CEBaB.cls.dropout.0.1.enc.dropout.0.1.counter.type.'\\\n",
    "                     f'{counterfactual_type}.k.{k}.int.layer.{interchange_layer}.'\\\n",
    "                     f'seed_{seed}/'\n",
    "\n",
    "    # load data from HF\n",
    "    cebab = datasets.load_dataset(\n",
    "        'CEBaB/CEBaB', use_auth_token=True,\n",
    "        cache_dir=\"../train_cache/\"\n",
    "    )\n",
    "\n",
    "    train, dev, test = preprocess_hf_dataset_inclusive(\n",
    "        cebab, verbose=1, dataset_type=dataset_type\n",
    "    )\n",
    "\n",
    "    eval_dataset = dev if eval_split == 'dev' else test\n",
    "\n",
    "    tf_model = model_module(\n",
    "        blackbox_model_path, \n",
    "        device=device, \n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    explainer = explainer_module(\n",
    "        blackbox_model_path,\n",
    "        cpm_model_path, \n",
    "        device=device, \n",
    "        batch_size=batch_size,\n",
    "        intervention_h_dim=h_dim,\n",
    "    )\n",
    "\n",
    "    result_per_example, ATE, CEBaB_metrics, CEBaB_metrics_per_aspect_direction, \\\n",
    "    CEBaB_metrics_per_aspect, CaCE_per_aspect_direction, \\\n",
    "    ACaCE_per_aspect, performance_report = cebab_pipeline(\n",
    "        tf_model, explainer, \n",
    "        train, eval_dataset,\n",
    "        seed, k, dataset_type=dataset_type, \n",
    "        shorten_model_name=False, \n",
    "        train_setting=\"inclusive\", \n",
    "        approximate=False if counterfactual_type == \"true\" else True\n",
    "    )\n",
    "    \n",
    "    results[grid_conditions] = (\n",
    "        result_per_example, ATE, CEBaB_metrics, CEBaB_metrics_per_aspect_direction, \\\n",
    "        CEBaB_metrics_per_aspect, CaCE_per_aspect_direction, \\\n",
    "        ACaCE_per_aspect, performance_report\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_split</th>\n",
       "      <th>control</th>\n",
       "      <th>seed</th>\n",
       "      <th>h_dim</th>\n",
       "      <th>interchange_layer</th>\n",
       "      <th>class_num</th>\n",
       "      <th>k</th>\n",
       "      <th>beta</th>\n",
       "      <th>gemma</th>\n",
       "      <th>model_arch</th>\n",
       "      <th>lr</th>\n",
       "      <th>counterfactual_type</th>\n",
       "      <th>ICaCE-L2</th>\n",
       "      <th>ICaCE-cosine</th>\n",
       "      <th>ICaCE-normdiff</th>\n",
       "      <th>macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>ks</td>\n",
       "      <td>42</td>\n",
       "      <td>192</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.8313</td>\n",
       "      <td>0.6325</td>\n",
       "      <td>0.5932</td>\n",
       "      <td>0.463772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>ks</td>\n",
       "      <td>42</td>\n",
       "      <td>192</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.7766</td>\n",
       "      <td>0.5422</td>\n",
       "      <td>0.6301</td>\n",
       "      <td>0.602434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>ks</td>\n",
       "      <td>42</td>\n",
       "      <td>192</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.7505</td>\n",
       "      <td>0.5187</td>\n",
       "      <td>0.6145</td>\n",
       "      <td>0.621132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>ks</td>\n",
       "      <td>42</td>\n",
       "      <td>192</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.7037</td>\n",
       "      <td>0.5135</td>\n",
       "      <td>0.5924</td>\n",
       "      <td>0.641056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>ks</td>\n",
       "      <td>42</td>\n",
       "      <td>192</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.4768</td>\n",
       "      <td>0.3923</td>\n",
       "      <td>0.2897</td>\n",
       "      <td>0.706076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test</td>\n",
       "      <td>ks</td>\n",
       "      <td>42</td>\n",
       "      <td>192</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>6000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.4583</td>\n",
       "      <td>0.3759</td>\n",
       "      <td>0.2674</td>\n",
       "      <td>0.707092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test</td>\n",
       "      <td>ks</td>\n",
       "      <td>42</td>\n",
       "      <td>192</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>9848</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.4655</td>\n",
       "      <td>0.3724</td>\n",
       "      <td>0.2906</td>\n",
       "      <td>0.695415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test</td>\n",
       "      <td>ks</td>\n",
       "      <td>42</td>\n",
       "      <td>192</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>19684</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.4295</td>\n",
       "      <td>0.3520</td>\n",
       "      <td>0.2547</td>\n",
       "      <td>0.699719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test</td>\n",
       "      <td>ks</td>\n",
       "      <td>66</td>\n",
       "      <td>192</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.9225</td>\n",
       "      <td>0.6711</td>\n",
       "      <td>0.5690</td>\n",
       "      <td>0.245234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test</td>\n",
       "      <td>ks</td>\n",
       "      <td>66</td>\n",
       "      <td>192</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.7494</td>\n",
       "      <td>0.5711</td>\n",
       "      <td>0.6197</td>\n",
       "      <td>0.659658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test</td>\n",
       "      <td>ks</td>\n",
       "      <td>66</td>\n",
       "      <td>192</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.7270</td>\n",
       "      <td>0.5485</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.671326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test</td>\n",
       "      <td>ks</td>\n",
       "      <td>66</td>\n",
       "      <td>192</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.7167</td>\n",
       "      <td>0.5343</td>\n",
       "      <td>0.5961</td>\n",
       "      <td>0.649855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>test</td>\n",
       "      <td>ks</td>\n",
       "      <td>66</td>\n",
       "      <td>192</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.4977</td>\n",
       "      <td>0.3919</td>\n",
       "      <td>0.3062</td>\n",
       "      <td>0.696651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>test</td>\n",
       "      <td>ks</td>\n",
       "      <td>66</td>\n",
       "      <td>192</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>6000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.4587</td>\n",
       "      <td>0.3740</td>\n",
       "      <td>0.2624</td>\n",
       "      <td>0.705486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test</td>\n",
       "      <td>ks</td>\n",
       "      <td>66</td>\n",
       "      <td>192</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>9848</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.4932</td>\n",
       "      <td>0.3767</td>\n",
       "      <td>0.3252</td>\n",
       "      <td>0.695353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>test</td>\n",
       "      <td>ks</td>\n",
       "      <td>66</td>\n",
       "      <td>192</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>19684</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.4703</td>\n",
       "      <td>0.3956</td>\n",
       "      <td>0.3171</td>\n",
       "      <td>0.683067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>test</td>\n",
       "      <td>ks</td>\n",
       "      <td>77</td>\n",
       "      <td>192</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.8862</td>\n",
       "      <td>0.6938</td>\n",
       "      <td>0.5787</td>\n",
       "      <td>0.374752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>test</td>\n",
       "      <td>ks</td>\n",
       "      <td>77</td>\n",
       "      <td>192</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.7788</td>\n",
       "      <td>0.5742</td>\n",
       "      <td>0.6478</td>\n",
       "      <td>0.616343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>test</td>\n",
       "      <td>ks</td>\n",
       "      <td>77</td>\n",
       "      <td>192</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.7762</td>\n",
       "      <td>0.5432</td>\n",
       "      <td>0.6657</td>\n",
       "      <td>0.662883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>test</td>\n",
       "      <td>ks</td>\n",
       "      <td>77</td>\n",
       "      <td>192</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.7620</td>\n",
       "      <td>0.5480</td>\n",
       "      <td>0.6374</td>\n",
       "      <td>0.622294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>test</td>\n",
       "      <td>ks</td>\n",
       "      <td>77</td>\n",
       "      <td>192</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.5290</td>\n",
       "      <td>0.4181</td>\n",
       "      <td>0.3569</td>\n",
       "      <td>0.704028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>test</td>\n",
       "      <td>ks</td>\n",
       "      <td>77</td>\n",
       "      <td>192</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>6000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.4807</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>0.2774</td>\n",
       "      <td>0.708957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>test</td>\n",
       "      <td>ks</td>\n",
       "      <td>77</td>\n",
       "      <td>192</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>9848</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.4396</td>\n",
       "      <td>0.3473</td>\n",
       "      <td>0.2503</td>\n",
       "      <td>0.711738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>test</td>\n",
       "      <td>ks</td>\n",
       "      <td>77</td>\n",
       "      <td>192</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>19684</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>true</td>\n",
       "      <td>0.4437</td>\n",
       "      <td>0.3451</td>\n",
       "      <td>0.2403</td>\n",
       "      <td>0.701776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eval_split control  seed  h_dim  interchange_layer  class_num      k  beta  \\\n",
       "0        test      ks    42    192                 10          5     10   1.0   \n",
       "1        test      ks    42    192                 10          5    100   1.0   \n",
       "2        test      ks    42    192                 10          5    500   1.0   \n",
       "3        test      ks    42    192                 10          5   1000   1.0   \n",
       "4        test      ks    42    192                 10          5   3000   1.0   \n",
       "5        test      ks    42    192                 10          5   6000   1.0   \n",
       "6        test      ks    42    192                 10          5   9848   1.0   \n",
       "7        test      ks    42    192                 10          5  19684   1.0   \n",
       "8        test      ks    66    192                 10          5     10   1.0   \n",
       "9        test      ks    66    192                 10          5    100   1.0   \n",
       "10       test      ks    66    192                 10          5    500   1.0   \n",
       "11       test      ks    66    192                 10          5   1000   1.0   \n",
       "12       test      ks    66    192                 10          5   3000   1.0   \n",
       "13       test      ks    66    192                 10          5   6000   1.0   \n",
       "14       test      ks    66    192                 10          5   9848   1.0   \n",
       "15       test      ks    66    192                 10          5  19684   1.0   \n",
       "16       test      ks    77    192                 10          5     10   1.0   \n",
       "17       test      ks    77    192                 10          5    100   1.0   \n",
       "18       test      ks    77    192                 10          5    500   1.0   \n",
       "19       test      ks    77    192                 10          5   1000   1.0   \n",
       "20       test      ks    77    192                 10          5   3000   1.0   \n",
       "21       test      ks    77    192                 10          5   6000   1.0   \n",
       "22       test      ks    77    192                 10          5   9848   1.0   \n",
       "23       test      ks    77    192                 10          5  19684   1.0   \n",
       "\n",
       "    gemma         model_arch     lr counterfactual_type  ICaCE-L2  \\\n",
       "0     3.0  bert-base-uncased  8e-05                true    0.8313   \n",
       "1     3.0  bert-base-uncased  8e-05                true    0.7766   \n",
       "2     3.0  bert-base-uncased  8e-05                true    0.7505   \n",
       "3     3.0  bert-base-uncased  8e-05                true    0.7037   \n",
       "4     3.0  bert-base-uncased  8e-05                true    0.4768   \n",
       "5     3.0  bert-base-uncased  8e-05                true    0.4583   \n",
       "6     3.0  bert-base-uncased  8e-05                true    0.4655   \n",
       "7     3.0  bert-base-uncased  8e-05                true    0.4295   \n",
       "8     3.0  bert-base-uncased  8e-05                true    0.9225   \n",
       "9     3.0  bert-base-uncased  8e-05                true    0.7494   \n",
       "10    3.0  bert-base-uncased  8e-05                true    0.7270   \n",
       "11    3.0  bert-base-uncased  8e-05                true    0.7167   \n",
       "12    3.0  bert-base-uncased  8e-05                true    0.4977   \n",
       "13    3.0  bert-base-uncased  8e-05                true    0.4587   \n",
       "14    3.0  bert-base-uncased  8e-05                true    0.4932   \n",
       "15    3.0  bert-base-uncased  8e-05                true    0.4703   \n",
       "16    3.0  bert-base-uncased  8e-05                true    0.8862   \n",
       "17    3.0  bert-base-uncased  8e-05                true    0.7788   \n",
       "18    3.0  bert-base-uncased  8e-05                true    0.7762   \n",
       "19    3.0  bert-base-uncased  8e-05                true    0.7620   \n",
       "20    3.0  bert-base-uncased  8e-05                true    0.5290   \n",
       "21    3.0  bert-base-uncased  8e-05                true    0.4807   \n",
       "22    3.0  bert-base-uncased  8e-05                true    0.4396   \n",
       "23    3.0  bert-base-uncased  8e-05                true    0.4437   \n",
       "\n",
       "    ICaCE-cosine  ICaCE-normdiff  macro-f1  \n",
       "0         0.6325          0.5932  0.463772  \n",
       "1         0.5422          0.6301  0.602434  \n",
       "2         0.5187          0.6145  0.621132  \n",
       "3         0.5135          0.5924  0.641056  \n",
       "4         0.3923          0.2897  0.706076  \n",
       "5         0.3759          0.2674  0.707092  \n",
       "6         0.3724          0.2906  0.695415  \n",
       "7         0.3520          0.2547  0.699719  \n",
       "8         0.6711          0.5690  0.245234  \n",
       "9         0.5711          0.6197  0.659658  \n",
       "10        0.5485          0.6147  0.671326  \n",
       "11        0.5343          0.5961  0.649855  \n",
       "12        0.3919          0.3062  0.696651  \n",
       "13        0.3740          0.2624  0.705486  \n",
       "14        0.3767          0.3252  0.695353  \n",
       "15        0.3956          0.3171  0.683067  \n",
       "16        0.6938          0.5787  0.374752  \n",
       "17        0.5742          0.6478  0.616343  \n",
       "18        0.5432          0.6657  0.662883  \n",
       "19        0.5480          0.6374  0.622294  \n",
       "20        0.4181          0.3569  0.704028  \n",
       "21        0.3857          0.2774  0.708957  \n",
       "22        0.3473          0.2503  0.711738  \n",
       "23        0.3451          0.2403  0.701776  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_keys = [\n",
    "    \"eval_split\",\n",
    "    \"control\", \"seed\", \n",
    "    \"h_dim\", \"interchange_layer\", \n",
    "    \"class_num\", \"k\", \n",
    "    \"beta\", \"gemma\", \n",
    "    \"model_arch\", \"lr\", \"counterfactual_type\"\n",
    "]\n",
    "values = []\n",
    "for k, v in results.items():\n",
    "    _values = []\n",
    "    for ik in important_keys:\n",
    "        _values.append(dict(k)[ik])\n",
    "    _values.append(v[2][\"ICaCE-L2\"].iloc[0])\n",
    "    _values.append(v[2][\"ICaCE-cosine\"].iloc[0])\n",
    "    _values.append(v[2][\"ICaCE-normdiff\"].iloc[0])\n",
    "    _values.append(v[-1].iloc[0][0])\n",
    "    values.append(_values)\n",
    "important_keys.extend([\"ICaCE-L2\", \"ICaCE-cosine\", \"ICaCE-normdiff\", \"macro-f1\"])\n",
    "df = pd.DataFrame(values, columns=important_keys)\n",
    "df.sort_values(by=['seed', 'interchange_layer', 'h_dim'], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregating results in the way you like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_key = \"k\"\n",
    "\n",
    "model_arch = grid[\"model_arch\"][0]\n",
    "control = grid[\"control\"][0]\n",
    "df.groupby([groupby_key], as_index=False).mean().to_csv(\n",
    "    f\"./csv-results/{model_arch}-{control}-mean.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([groupby_key], as_index=False).std().to_csv(\n",
    "    f\"./csv-results/{model_arch}-{control}-std.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>seed</th>\n",
       "      <th>h_dim</th>\n",
       "      <th>interchange_layer</th>\n",
       "      <th>class_num</th>\n",
       "      <th>beta</th>\n",
       "      <th>gemma</th>\n",
       "      <th>ICaCE-L2</th>\n",
       "      <th>ICaCE-cosine</th>\n",
       "      <th>ICaCE-normdiff</th>\n",
       "      <th>macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>61.666667</td>\n",
       "      <td>192.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.665800</td>\n",
       "      <td>0.580300</td>\n",
       "      <td>0.361253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>61.666667</td>\n",
       "      <td>192.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.768267</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.632533</td>\n",
       "      <td>0.626145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>61.666667</td>\n",
       "      <td>192.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.751233</td>\n",
       "      <td>0.536800</td>\n",
       "      <td>0.631633</td>\n",
       "      <td>0.651780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>61.666667</td>\n",
       "      <td>192.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.727467</td>\n",
       "      <td>0.531933</td>\n",
       "      <td>0.608633</td>\n",
       "      <td>0.637735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000</td>\n",
       "      <td>61.666667</td>\n",
       "      <td>192.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.501167</td>\n",
       "      <td>0.400767</td>\n",
       "      <td>0.317600</td>\n",
       "      <td>0.702252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6000</td>\n",
       "      <td>61.666667</td>\n",
       "      <td>192.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.465900</td>\n",
       "      <td>0.378533</td>\n",
       "      <td>0.269067</td>\n",
       "      <td>0.707178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9848</td>\n",
       "      <td>61.666667</td>\n",
       "      <td>192.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.466100</td>\n",
       "      <td>0.365467</td>\n",
       "      <td>0.288700</td>\n",
       "      <td>0.700836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19684</td>\n",
       "      <td>61.666667</td>\n",
       "      <td>192.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.447833</td>\n",
       "      <td>0.364233</td>\n",
       "      <td>0.270700</td>\n",
       "      <td>0.694854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       k       seed  h_dim  interchange_layer  class_num  beta  gemma  \\\n",
       "0     10  61.666667  192.0               10.0        5.0   1.0    3.0   \n",
       "1    100  61.666667  192.0               10.0        5.0   1.0    3.0   \n",
       "2    500  61.666667  192.0               10.0        5.0   1.0    3.0   \n",
       "3   1000  61.666667  192.0               10.0        5.0   1.0    3.0   \n",
       "4   3000  61.666667  192.0               10.0        5.0   1.0    3.0   \n",
       "5   6000  61.666667  192.0               10.0        5.0   1.0    3.0   \n",
       "6   9848  61.666667  192.0               10.0        5.0   1.0    3.0   \n",
       "7  19684  61.666667  192.0               10.0        5.0   1.0    3.0   \n",
       "\n",
       "   ICaCE-L2  ICaCE-cosine  ICaCE-normdiff  macro-f1  \n",
       "0  0.880000      0.665800        0.580300  0.361253  \n",
       "1  0.768267      0.562500        0.632533  0.626145  \n",
       "2  0.751233      0.536800        0.631633  0.651780  \n",
       "3  0.727467      0.531933        0.608633  0.637735  \n",
       "4  0.501167      0.400767        0.317600  0.702252  \n",
       "5  0.465900      0.378533        0.269067  0.707178  \n",
       "6  0.466100      0.365467        0.288700  0.700836  \n",
       "7  0.447833      0.364233        0.270700  0.694854  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([groupby_key], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>seed</th>\n",
       "      <th>h_dim</th>\n",
       "      <th>interchange_layer</th>\n",
       "      <th>class_num</th>\n",
       "      <th>beta</th>\n",
       "      <th>gemma</th>\n",
       "      <th>ICaCE-L2</th>\n",
       "      <th>ICaCE-cosine</th>\n",
       "      <th>ICaCE-normdiff</th>\n",
       "      <th>macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>17.897858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045915</td>\n",
       "      <td>0.030992</td>\n",
       "      <td>0.012179</td>\n",
       "      <td>0.109893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>17.897858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016376</td>\n",
       "      <td>0.017649</td>\n",
       "      <td>0.014207</td>\n",
       "      <td>0.029845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>17.897858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024608</td>\n",
       "      <td>0.015897</td>\n",
       "      <td>0.029503</td>\n",
       "      <td>0.026876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>17.897858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030605</td>\n",
       "      <td>0.017371</td>\n",
       "      <td>0.024981</td>\n",
       "      <td>0.014077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000</td>\n",
       "      <td>17.897858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026272</td>\n",
       "      <td>0.015012</td>\n",
       "      <td>0.035020</td>\n",
       "      <td>0.004957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6000</td>\n",
       "      <td>17.897858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012819</td>\n",
       "      <td>0.006279</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>0.001737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9848</td>\n",
       "      <td>17.897858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026805</td>\n",
       "      <td>0.015879</td>\n",
       "      <td>0.037486</td>\n",
       "      <td>0.009442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19684</td>\n",
       "      <td>17.897858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020712</td>\n",
       "      <td>0.027383</td>\n",
       "      <td>0.040824</td>\n",
       "      <td>0.010259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       k       seed  h_dim  interchange_layer  class_num  beta  gemma  \\\n",
       "0     10  17.897858    0.0                0.0        0.0   0.0    0.0   \n",
       "1    100  17.897858    0.0                0.0        0.0   0.0    0.0   \n",
       "2    500  17.897858    0.0                0.0        0.0   0.0    0.0   \n",
       "3   1000  17.897858    0.0                0.0        0.0   0.0    0.0   \n",
       "4   3000  17.897858    0.0                0.0        0.0   0.0    0.0   \n",
       "5   6000  17.897858    0.0                0.0        0.0   0.0    0.0   \n",
       "6   9848  17.897858    0.0                0.0        0.0   0.0    0.0   \n",
       "7  19684  17.897858    0.0                0.0        0.0   0.0    0.0   \n",
       "\n",
       "   ICaCE-L2  ICaCE-cosine  ICaCE-normdiff  macro-f1  \n",
       "0  0.045915      0.030992        0.012179  0.109893  \n",
       "1  0.016376      0.017649        0.014207  0.029845  \n",
       "2  0.024608      0.015897        0.029503  0.026876  \n",
       "3  0.030605      0.017371        0.024981  0.014077  \n",
       "4  0.026272      0.015012        0.035020  0.004957  \n",
       "5  0.012819      0.006279        0.007638  0.001737  \n",
       "6  0.026805      0.015879        0.037486  0.009442  \n",
       "7  0.020712      0.027383        0.040824  0.010259  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([groupby_key], as_index=False).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save your results somewhere and load again to tabularize your results altogether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name = input(\"Plase give an output file name: \")\n",
    "\n",
    "output_directory = f'../proxy_training_results/{model_path}/'\n",
    "output_filename = os.path.join(output_directory, f'{output_name}.pkl')\n",
    "print(\"Writing to file: \", output_filename)\n",
    "with open(output_filename, 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

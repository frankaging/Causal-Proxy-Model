{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating CPM with CEBaB\n",
    "Our Causal Proxy Model (CPM) is for providing concept-based explanation for a blackbox model. We use newly developed CEBaB benchmark for comparing CPM with other concept-based explanation methods. This notebook evaluates CPM with CEBaB benchmark under different settings.\n",
    "\n",
    "More importantly, we introduce new baselines for CPM as well. Formally, we evaluate the blackbox model with interchange intervention evaluation (which will be introduced in details below).\n",
    "\n",
    "In this notebook, we can evaluate the following models:\n",
    "- CPM: `BERT-base-uncased`\n",
    "- CPM: `RoBERTa-base`\n",
    "- CPM: `GPT2`\n",
    "- CPM: `LSTM+GloVe`\n",
    "- CPM: `Control`\n",
    "\n",
    "and we can evaluate with the following conditions:\n",
    "- 2-class\n",
    "- 3-class\n",
    "- 5-class\n",
    "\n",
    "and this script also support evaluates experiments with different control conditions:\n",
    "- `control=True`\n",
    "- `control=False`\n",
    "- `control=\"pretrain\"`\n",
    "- `control=\"random\"`\n",
    "- `control=\"finetune\"`\n",
    "- `control=\"fewshots\"` (supports BERT only)\n",
    "- `control=\"fewshots-augment\"` (supports BERT only)\n",
    "- `control=\"layer\"` (supports BERT only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs import *\n",
    "from modelings.modelings_bert import *\n",
    "from modelings.modelings_roberta import *\n",
    "from modelings.modelings_gpt2 import *\n",
    "from modelings.modelings_lstm import *\n",
    "\"\"\"\n",
    "For evaluate, we use a single random seed, as\n",
    "the models are trained with 5 different seeds\n",
    "already.\n",
    "\"\"\"\n",
    "_ = random.seed(123)\n",
    "_ = np.random.seed(123)\n",
    "_ = torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main evaluate script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The following blocks will run CEBaB benchmark in\n",
    "all the combinations of the following conditions.\n",
    "\"\"\"\n",
    "grid = {\n",
    "    \"seed\": [42],\n",
    "    \"h_dim\": [192], # 1, 4, 16, 32, 64, 128, 192\n",
    "    \"class_num\": [5],\n",
    "    \"control\": [\"dev\"],\n",
    "    # True, False, pretrain, random, finetune, \n",
    "    # fewshots fewshots-augment fewshots-layer\n",
    "    # fewshots-hdim\n",
    "    # fewshots-augment-balance\n",
    "    # fewshots-augment-large-epochs\n",
    "    # approximate-large-epochs\n",
    "    # fewshots-augment-large-epochs-no-probe\n",
    "    \"beta\" : [1.0],\n",
    "    \"gemma\" : [3.0],\n",
    "    \"cls_dropout\" : [0.1],\n",
    "    \"enc_dropout\" : [0.1],\n",
    "    \"model_arch\" : [\"bert-base-uncased\"],\n",
    "    \"true_cfc\" : [1755], \n",
    "    # only used for fewshots evaluations.\n",
    "    # 5, 50, 200, 600, 1200, 1755\n",
    "    \"interchange_layer\" : [12]\n",
    "}\n",
    "\n",
    "keys, values = zip(*grid.items())\n",
    "permutations_dicts = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "device = 'cuda:0'\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalProxyModelForBERT(Explainer, CausalExplainer):\n",
    "    def __init__(\n",
    "        self, \n",
    "        blackbox_model_path,\n",
    "        cpm_model_path, \n",
    "        device, batch_size, \n",
    "        intervention_h_dim=1,\n",
    "        min_iit_pair_examples=1,\n",
    "        match_non_int_type=False,\n",
    "        cache_dir=\"../../huggingface_cache\",\n",
    "    ):\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.min_iit_pair_examples = min_iit_pair_examples\n",
    "        self.match_non_int_type = match_non_int_type\n",
    "        # blackbox model loading.\n",
    "        self.blackbox_model = BertForNonlinearSequenceClassification.from_pretrained(\n",
    "            blackbox_model_path,\n",
    "            cache_dir=cache_dir\n",
    "        )\n",
    "        self.blackbox_model.to(device)\n",
    "        \n",
    "        # causal proxy model loading.\n",
    "        cpm_config = AutoConfig.from_pretrained(\n",
    "            cpm_model_path,\n",
    "            cache_dir=cache_dir,\n",
    "            use_auth_token=True if \"CEBaB/\" in cpm_model_path else False,\n",
    "        )\n",
    "        try:\n",
    "            cpm_config.intervention_h_dim = cpm_config.intervention_h_dim\n",
    "        except:\n",
    "            cpm_config.intervention_h_dim = intervention_h_dim\n",
    "        print(f\"intervention_h_dim={cpm_config.intervention_h_dim}\")\n",
    "        cpm_model = IITBERTForSequenceClassification.from_pretrained(\n",
    "            cpm_model_path,\n",
    "            config=cpm_config,\n",
    "            cache_dir=cache_dir\n",
    "        )\n",
    "        cpm_model.to(device)\n",
    "        self.cpm_model = InterventionableIITTransformerForSequenceClassification(\n",
    "            model=cpm_model\n",
    "        )\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        \n",
    "    def preprocess_predict_proba(self, df):\n",
    "        x = self.tokenizer(df['description'].to_list(), padding=True, truncation=True, return_tensors='pt')\n",
    "        y = df['review_majority'].astype(int)\n",
    "\n",
    "        return x, y\n",
    "        \n",
    "    def predict_proba(self, dataset):\n",
    "        self.cpm_model.model.eval()\n",
    "\n",
    "        x, y = self.preprocess_predict_proba(dataset)\n",
    "\n",
    "        # get the predictions batch per batch\n",
    "        probas = []\n",
    "        for i in range(ceil(len(dataset) / self.batch_size)):\n",
    "            x_batch = {k: v[i * self.batch_size:(i + 1) * self.batch_size].to(self.device) for k, v in x.items()}\n",
    "            probas.append(torch.nn.functional.softmax(self.cpm_model.model(**x_batch).logits[0].cpu(), dim=-1).detach())\n",
    "\n",
    "        probas = torch.concat(probas)\n",
    "        probas = np.round(probas.numpy(), decimals=16)\n",
    "\n",
    "        predictions = np.argmax(probas, axis=1)\n",
    "        clf_report = classification_report(y.to_numpy(), predictions, output_dict=True)\n",
    "\n",
    "        return probas, clf_report\n",
    "        \n",
    "    def fit(self, dataset, classifier_predictions, classifier, dev_dataset=None):\n",
    "        # we don't need to train IIT here.\n",
    "        pass\n",
    "    \n",
    "    def preprocess(self, pairs_dataset, dev_dataset):\n",
    "        \n",
    "        # configs\n",
    "        min_iit_pair_examples = self.min_iit_pair_examples\n",
    "        match_non_int_type = self.match_non_int_type\n",
    "        \n",
    "        query_dataset = get_iit_examples(dev_dataset)\n",
    "        iit_pairs_dataset = []\n",
    "        iit_id = 0\n",
    "        for index, row in pairs_dataset.iterrows():\n",
    "            query_description_base = row['description_base']\n",
    "            query_int_type = row['intervention_type']\n",
    "            query_non_int_type = {\n",
    "                \"ambiance\", \"food\", \"noise\", \"service\"\n",
    "            } - {query_int_type}\n",
    "            query_int_aspect_base = row[\"intervention_aspect_base\"]\n",
    "            query_int_aspect_assignment = row['intervention_aspect_counterfactual']\n",
    "            query_original_id = row[\"original_id_base\"]\n",
    "            matched_iit_examples = query_dataset[\n",
    "                (query_dataset[f\"{query_int_type}_aspect_majority\"]==query_int_aspect_assignment)&\n",
    "                (query_dataset[\"original_id\"]!=query_original_id)\n",
    "            ]\n",
    "            if match_non_int_type:\n",
    "                for _t in query_non_int_type:\n",
    "                    matched_iit_examples = matched_iit_examples[\n",
    "                        (matched_iit_examples[f\"{_t}_aspect_majority\"]==\\\n",
    "                         row[f\"{_t}_aspect_majority_base\"])\n",
    "                    ]\n",
    "            if len(set(matched_iit_examples[\"id\"])) < min_iit_pair_examples:\n",
    "                if match_non_int_type:\n",
    "                    # simply avoid mapping the rest of the aspects.\n",
    "                    matched_iit_examples = query_dataset[\n",
    "                        (query_dataset[f\"{query_int_type}_aspect_majority\"]==query_int_aspect_assignment)&\n",
    "                        (query_dataset[\"original_id\"]!=query_original_id)\n",
    "                    ]\n",
    "                else:\n",
    "                    assert False # we need to check the number!\n",
    "            sampled_iit_example_ids = random.sample(\n",
    "                set(matched_iit_examples[\"id\"]), min_iit_pair_examples\n",
    "            )\n",
    "            for _id in sampled_iit_example_ids:\n",
    "                description_iit = query_dataset[query_dataset[\"id\"]==_id][\"description\"].iloc[0]\n",
    "                iit_pairs_dataset += [[\n",
    "                    iit_id,\n",
    "                    query_int_type,\n",
    "                    query_description_base, \n",
    "                    description_iit\n",
    "                ]]\n",
    "            iit_id += 1\n",
    "        iit_pairs_dataset = pd.DataFrame(\n",
    "            columns=[\n",
    "                'iit_id',\n",
    "                'intervention_type', \n",
    "                'description_base', \n",
    "                'description_iit'], \n",
    "            data=iit_pairs_dataset\n",
    "        )\n",
    "        \n",
    "        base_x = self.tokenizer(\n",
    "            iit_pairs_dataset['description_base'].to_list(), \n",
    "            padding=True, truncation=True, return_tensors='pt'\n",
    "        )\n",
    "        source_x = self.tokenizer(\n",
    "            iit_pairs_dataset['description_iit'].to_list(), \n",
    "            padding=True, truncation=True, return_tensors='pt'\n",
    "        )\n",
    "        intervention_corr = []\n",
    "        for _type in iit_pairs_dataset[\"intervention_type\"].tolist():\n",
    "            if _type == \"ambiance\":\n",
    "                intervention_corr += [0]\n",
    "            if _type == \"food\":\n",
    "                intervention_corr += [1]\n",
    "            if _type == \"noise\":\n",
    "                intervention_corr += [2]\n",
    "            if _type == \"service\":\n",
    "                intervention_corr += [3]\n",
    "        intervention_corr = torch.tensor(intervention_corr).long()\n",
    "        return base_x, source_x, intervention_corr, iit_pairs_dataset\n",
    "    \n",
    "    def estimate_icace(self, pairs, df):\n",
    "        CPM_iTEs = []\n",
    "        # self.blackbox_model.eval()\n",
    "        # self.cpm_model.model.eval()\n",
    "        base_x, source_x, intervention_corr, iit_pairs_dataset = self.preprocess(\n",
    "            pairs, df\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            for i in tqdm(range(ceil(len(iit_pairs_dataset)/self.batch_size))):\n",
    "                base_x_batch = {k:v[i*self.batch_size:(i+1)*self.batch_size].to(self.device) for k,v in base_x.items()} \n",
    "                source_x_batch = {k:v[i*self.batch_size:(i+1)*self.batch_size].to(self.device) for k,v in source_x.items()} \n",
    "                intervention_corr_batch = intervention_corr[i*self.batch_size:(i+1)*self.batch_size].to(self.device)\n",
    "                \n",
    "                base_outputs = torch.nn.functional.softmax(\n",
    "                    self.blackbox_model(**base_x_batch).logits.cpu(), dim=-1\n",
    "                ).detach()\n",
    "                _, _, counterfactual_outputs = self.cpm_model.forward(\n",
    "                    base=(base_x_batch['input_ids'], base_x_batch['attention_mask']),\n",
    "                    source=(source_x_batch['input_ids'], source_x_batch['attention_mask']),\n",
    "                    base_intervention_corr=intervention_corr_batch,\n",
    "                    source_intervention_corr=intervention_corr_batch,\n",
    "                )\n",
    "                counterfactual_outputs = torch.nn.functional.softmax(\n",
    "                    counterfactual_outputs[\"logits\"][0].cpu(), dim=-1\n",
    "                ).detach()\n",
    "                CPM_iTE = counterfactual_outputs-base_outputs\n",
    "                CPM_iTEs.append(CPM_iTE)\n",
    "        CPM_iTEs = torch.concat(CPM_iTEs)\n",
    "        CPM_iTEs = np.round(CPM_iTEs.numpy(), decimals=4)\n",
    "\n",
    "        # only for iit explainer!\n",
    "        iit_pairs_dataset[\"EiCaCE\"] = list(CPM_iTEs)\n",
    "        CPM_iTEs = list(iit_pairs_dataset.groupby([\"iit_id\"])[\"EiCaCE\"].mean())\n",
    "        \n",
    "        return CPM_iTEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for this setting:  (('seed', 42), ('class_num', 5), ('beta', 1.0), ('gemma', 3.0), ('h_dim', 192), ('dataset_type', '5-way'), ('correction_epsilon', None), ('cls_dropout', 0.1), ('enc_dropout', 0.1), ('control', 'dev'), ('model_arch', 'bert-base-uncased'), ('true_cfc', 1755), ('interchange_layer', 12))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration CEBaB--CEBaB-0e2f7ed67c9d7e55\n",
      "Reusing dataset parquet (../train_cache/CEBaB___parquet/CEBaB--CEBaB-0e2f7ed67c9d7e55/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a864c341cce482c9b7204487716a64f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping no majority reviews: 16.6382% of train dataset.\n",
      "intervention_h_dim=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:28<00:00,  4.42it/s]\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for i in range(len(permutations_dicts)):\n",
    "    \n",
    "    seed=permutations_dicts[i][\"seed\"]\n",
    "    class_num=permutations_dicts[i][\"class_num\"]\n",
    "    beta=permutations_dicts[i][\"beta\"]\n",
    "    gemma=permutations_dicts[i][\"gemma\"]\n",
    "    h_dim=permutations_dicts[i][\"h_dim\"]\n",
    "    dataset_type = f'{class_num}-way'\n",
    "    correction_epsilon=None\n",
    "    cls_dropout=permutations_dicts[i][\"cls_dropout\"]\n",
    "    enc_dropout=permutations_dicts[i][\"enc_dropout\"]\n",
    "    control=permutations_dicts[i][\"control\"]\n",
    "    model_arch=permutations_dicts[i][\"model_arch\"]\n",
    "    true_cfc=permutations_dicts[i][\"true_cfc\"]\n",
    "    interchange_layer=permutations_dicts[i][\"interchange_layer\"]\n",
    "    \n",
    "    if model_arch == \"bert-base-uncased\":\n",
    "        model_path = \"BERT-results\" if control == False \\\n",
    "            else \"BERT-control-results\" if control == True \\\n",
    "            else f\"BERT-{control}-results\"\n",
    "        model_module = BERTForCEBaB\n",
    "        explainer_module = CausalProxyModelForBERT\n",
    "    elif model_arch == \"roberta-base\":\n",
    "        model_path = \"RoBERTa-results\" if control == False \\\n",
    "            else \"RoBERTa-control-results\" if control == True \\\n",
    "            else f\"RoBERTa-{control}-results\" \n",
    "        model_module = RoBERTaForCEBaB\n",
    "        explainer_module = CausalProxyModelForRoBERTa\n",
    "    elif model_arch == \"gpt2\":\n",
    "        model_path = \"gpt2-results\" if control == False \\\n",
    "            else \"gpt2-control-results\" if control == True \\\n",
    "            else f\"gpt2-{control}-results\"\n",
    "        model_module = GPT2ForCEBaB\n",
    "        explainer_module = CausalProxyModelForGPT2\n",
    "    elif model_arch == \"lstm\":\n",
    "        model_path = \"lstm-results\" if control == False \\\n",
    "            else \"lstm-control-results\" if control == True \\\n",
    "            else f\"lstm-{control}-results\"\n",
    "        model_module = LSTMForCEBaB\n",
    "        explainer_module = CausalProxyModelForLSTM\n",
    "        \n",
    "    grid_conditions=(\n",
    "        (\"seed\", seed),\n",
    "        (\"class_num\", class_num),\n",
    "        (\"beta\", beta),\n",
    "        (\"gemma\", gemma),\n",
    "        (\"h_dim\", h_dim),\n",
    "        (\"dataset_type\", dataset_type),\n",
    "        (\"correction_epsilon\", correction_epsilon),\n",
    "        (\"cls_dropout\", cls_dropout),\n",
    "        (\"enc_dropout\", enc_dropout),\n",
    "        (\"control\", control),\n",
    "        (\"model_arch\", model_arch),\n",
    "        (\"true_cfc\", true_cfc),\n",
    "        (\"interchange_layer\", interchange_layer)\n",
    "    )\n",
    "    print(\"Running for this setting: \", grid_conditions)\n",
    "\n",
    "    blackbox_model_path = f'CEBaB/{model_arch}.CEBaB.sa.{class_num}-class.exclusive.seed_{seed}'\n",
    "    if control == \"finetune\": # not for other control cases, e.g., random or pretrain\n",
    "        cpm_model_path = blackbox_model_path\n",
    "    else:\n",
    "        split_name = \"train\"\n",
    "        cpm_model_path = '../proxy_training_results/dev/'\\\n",
    "                         'cebab.alpha.1.0.beta.1.0.gemma.3.0'\\\n",
    "                         '.lr.8e-05.dim.192.hightype.bert-base-uncased'\\\n",
    "                         '.CEBaB.cls.dropout.0.1.enc.dropout.0.1.counter'\\\n",
    "                         '.type.true.k.19684.int.layer.10.seed_42/'\n",
    "        if control == \"dev\":\n",
    "            pass\n",
    "    # load data from HF\n",
    "    cebab = datasets.load_dataset(\n",
    "        'CEBaB/CEBaB', use_auth_token=True,\n",
    "        cache_dir=\"../train_cache/\"\n",
    "    )\n",
    "    train, dev, test = preprocess_hf_dataset(\n",
    "        cebab, one_example_per_world=True, \n",
    "        verbose=1, dataset_type=dataset_type\n",
    "    )\n",
    "\n",
    "    tf_model = model_module(\n",
    "        blackbox_model_path, \n",
    "        device=device, \n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    explanator = explainer_module(\n",
    "        blackbox_model_path,\n",
    "        cpm_model_path, \n",
    "        device=device, \n",
    "        batch_size=batch_size,\n",
    "        intervention_h_dim=h_dim,\n",
    "    )\n",
    "\n",
    "    train_dataset = train.copy()\n",
    "    dev_dataset = test.copy()\n",
    "\n",
    "    result_per_example, ATE, CEBaB_metrics, CEBaB_metrics_per_aspect_direction, \\\n",
    "    CEBaB_metrics_per_aspect, CaCE_per_aspect_direction, \\\n",
    "    ACaCE_per_aspect, performance_report = cebab_pipeline(\n",
    "        tf_model, explanator, \n",
    "        train_dataset, dev_dataset, \n",
    "        dataset_type=dataset_type,\n",
    "        correction_epsilon=correction_epsilon,\n",
    "    )\n",
    "    \n",
    "    results[grid_conditions] = (\n",
    "        result_per_example, ATE, CEBaB_metrics, CEBaB_metrics_per_aspect_direction, \\\n",
    "        CEBaB_metrics_per_aspect, CaCE_per_aspect_direction, \\\n",
    "        ACaCE_per_aspect, performance_report\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>h_dim</th>\n",
       "      <th>class_num</th>\n",
       "      <th>control</th>\n",
       "      <th>beta</th>\n",
       "      <th>gemma</th>\n",
       "      <th>cls_dropout</th>\n",
       "      <th>enc_dropout</th>\n",
       "      <th>model_arch</th>\n",
       "      <th>true_cfc</th>\n",
       "      <th>interchange_layer</th>\n",
       "      <th>ICaCE-L2</th>\n",
       "      <th>ICaCE-cosine</th>\n",
       "      <th>ICaCE-normdiff</th>\n",
       "      <th>macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>192</td>\n",
       "      <td>5</td>\n",
       "      <td>dev</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>1755</td>\n",
       "      <td>12</td>\n",
       "      <td>0.4481</td>\n",
       "      <td>0.3582</td>\n",
       "      <td>0.2465</td>\n",
       "      <td>0.68596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seed  h_dim  class_num control  beta  gemma  cls_dropout  enc_dropout  \\\n",
       "0    42    192          5     dev   1.0    3.0          0.1          0.1   \n",
       "\n",
       "          model_arch  true_cfc  interchange_layer  ICaCE-L2  ICaCE-cosine  \\\n",
       "0  bert-base-uncased      1755                 12    0.4481        0.3582   \n",
       "\n",
       "   ICaCE-normdiff  macro-f1  \n",
       "0          0.2465   0.68596  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_keys = [\n",
    "    \"seed\", \"h_dim\", \"class_num\", \n",
    "    \"control\", \"beta\", \"gemma\", \n",
    "    \"cls_dropout\", \"enc_dropout\", \n",
    "    \"model_arch\", \"true_cfc\", \n",
    "    \"interchange_layer\"\n",
    "]\n",
    "values = []\n",
    "for k, v in results.items():\n",
    "    _values = []\n",
    "    for ik in important_keys:\n",
    "        _values.append(dict(k)[ik])\n",
    "    _values.append(v[2][\"ICaCE-L2\"].iloc[0])\n",
    "    _values.append(v[2][\"ICaCE-cosine\"].iloc[0])\n",
    "    _values.append(v[2][\"ICaCE-normdiff\"].iloc[0])\n",
    "    _values.append(v[-1].iloc[0][0])\n",
    "    values.append(_values)\n",
    "important_keys.extend([\"ICaCE-L2\", \"ICaCE-cosine\", \"ICaCE-normdiff\", \"macro-f1\"])\n",
    "df = pd.DataFrame(values, columns=important_keys)\n",
    "df.sort_values(by=['class_num'], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save your results somewhere and load again to tabularize your results altogether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plase give an output file name: results\n",
      "Writing to file:  ../proxy_training_results/BERT-fewshots-hdim-results/results.pkl\n"
     ]
    }
   ],
   "source": [
    "output_name = input(\"Plase give an output file name: \")\n",
    "\n",
    "output_directory = f'../proxy_training_results/{model_path}/'\n",
    "output_filename = os.path.join(output_directory, f'{output_name}.pkl')\n",
    "print(\"Writing to file: \", output_filename)\n",
    "with open(output_filename, 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

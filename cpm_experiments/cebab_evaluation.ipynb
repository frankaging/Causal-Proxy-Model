{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating CPM with CEBaB\n",
    "Our Causal Proxy Model (CPM) is for providing concept-based explanation for a blackbox model. We use newly developed CEBaB benchmark for comparing CPM with other concept-based explanation methods. This notebook evaluates CPM with CEBaB benchmark under different settings.\n",
    "\n",
    "More importantly, we introduce new baselines for CPM as well. Formally, we evaluate the blackbox model with interchange intervention evaluation (which will be introduced in details below).\n",
    "\n",
    "In this notebook, we will evaluate the following models:\n",
    "- CPM: `BERT-base-uncased`\n",
    "- CPM: `RoBERTa-base`\n",
    "- CPM: `GPT2`\n",
    "- CPM: `LSTM+GloVe`\n",
    "- CPM: `Control`\n",
    "\n",
    "and we will evaluate with the following conditions:\n",
    "- 2-class\n",
    "- 3-class\n",
    "- 5-class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs import *\n",
    "\"\"\"\n",
    "For evaluate, we use a single random seed, as\n",
    "the models are trained with 5 different seeds\n",
    "already.\n",
    "\"\"\"\n",
    "_ = random.seed(123)\n",
    "_ = np.random.seed(123)\n",
    "_ = torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO:\n",
    "After this notebook is fully constructed, the following\n",
    "section needs to be separated out to another file.\n",
    "\"\"\"\n",
    "class BERTForCEBaB(Model):\n",
    "    def __init__(self, model_path, device='cpu', batch_size=64):\n",
    "        self.device = device\n",
    "        self.model_path = model_path\n",
    "        self.tokenizer_path = model_path\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.model = BertForNonlinearSequenceClassification.from_pretrained(\n",
    "            self.model_path,\n",
    "            cache_dir=\"../../huggingface_cache\"\n",
    "        )\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "        self.model.to(device)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.model_path.split('/')[-1]\n",
    "\n",
    "    def preprocess(self, df):\n",
    "        x = self.tokenizer(df['description'].to_list(), padding=True, truncation=True, return_tensors='pt')\n",
    "        y = df['review_majority'].astype(int)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def fit(self, dataset):\n",
    "        # assume model was already trained\n",
    "        pass\n",
    "\n",
    "    def predict_proba(self, dataset):\n",
    "        self.model.eval()\n",
    "\n",
    "        x, y = self.preprocess(dataset)\n",
    "\n",
    "        # get the predictions batch per batch\n",
    "        probas = []\n",
    "        for i in range(ceil(len(dataset) / self.batch_size)):\n",
    "            x_batch = {k: v[i * self.batch_size:(i + 1) * self.batch_size].to(self.device) for k, v in x.items()}\n",
    "            probas.append(torch.nn.functional.softmax(self.model(**x_batch).logits.cpu(), dim=-1).detach())\n",
    "\n",
    "        probas = torch.concat(probas)\n",
    "        probas = np.round(probas.numpy(), decimals=16)\n",
    "\n",
    "        predictions = np.argmax(probas, axis=1)\n",
    "        clf_report = classification_report(y.to_numpy(), predictions, output_dict=True)\n",
    "\n",
    "        return probas, clf_report\n",
    "\n",
    "    def get_embeddings(self, sentences_list):\n",
    "        x = self.tokenizer(sentences_list, padding=True, truncation=True, return_tensors='pt')\n",
    "        embeddings = []\n",
    "        for i in range(ceil(len(x['input_ids']) / self.batch_size)):\n",
    "            x_batch = {k: v[i * self.batch_size:(i + 1) * self.batch_size].to(self.device) for k, v in x.items()}\n",
    "            embeddings.append(self.model.base_model(**x_batch).pooler_output.detach().cpu().tolist())\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    def get_classification_head(self):\n",
    "        return self.model.classifier\n",
    "    \n",
    "def get_iit_examples(df):\n",
    "    \"\"\"\n",
    "    Given a dataframe in the new data scheme, return all intervention pairs.\n",
    "    \"\"\"\n",
    "    # Drop label distribution and worker information.\n",
    "    columns_to_keep = ['id', 'original_id', 'edit_id', 'is_original', 'edit_goal', 'edit_type', 'description', 'review_majority','food_aspect_majority', 'ambiance_aspect_majority', 'service_aspect_majority', 'noise_aspect_majority']\n",
    "    columns_to_keep += [col for col in df.columns if 'prediction' in col]\n",
    "    df = df[columns_to_keep]\n",
    "    return df\n",
    "\n",
    "class CausalProxyModelForBERT(Explainer):\n",
    "    def __init__(\n",
    "        self, \n",
    "        blackbox_model_path,\n",
    "        cpm_model_path, \n",
    "        device, batch_size, \n",
    "        intervention_h_dim=1,\n",
    "        min_iit_pair_examples=1,\n",
    "        match_non_int_type=False,\n",
    "        cache_dir=\"../../huggingface_cache\",\n",
    "    ):\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.min_iit_pair_examples = min_iit_pair_examples\n",
    "        self.match_non_int_type = match_non_int_type\n",
    "        # blackbox model loading.\n",
    "        self.blackbox_model = BertForNonlinearSequenceClassification.from_pretrained(\n",
    "            blackbox_model_path,\n",
    "            cache_dir=cache_dir\n",
    "        )\n",
    "        self.blackbox_model.to(device)\n",
    "        \n",
    "        # causal proxy model loading.\n",
    "        cpm_config = AutoConfig.from_pretrained(\n",
    "            cpm_model_path,\n",
    "            cache_dir=cache_dir,\n",
    "            use_auth_token=True if \"CEBaB/\" in cpm_model_path else False,\n",
    "        )\n",
    "        try:\n",
    "            cpm_config.intervention_h_dim = cpm_config.intervention_h_dim\n",
    "        except:\n",
    "            cpm_config.intervention_h_dim = intervention_h_dim\n",
    "        print(f\"intervention_h_dim={cpm_config.intervention_h_dim}\")\n",
    "        cpm_model = IITBERTForSequenceClassification.from_pretrained(\n",
    "            cpm_model_path,\n",
    "            config=cpm_config,\n",
    "            cache_dir=cache_dir\n",
    "        )\n",
    "        cpm_model.to(device)\n",
    "        self.cpm_model = InterventionableIITTransformerForSequenceClassification(\n",
    "            model=cpm_model\n",
    "        )\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        \n",
    "    def fit(self, dataset, classifier_predictions, classifier, dev_dataset=None):\n",
    "        # we don't need to train IIT here.\n",
    "        pass\n",
    "    \n",
    "    def preprocess(self, pairs_dataset, dev_dataset):\n",
    "        \n",
    "        # configs\n",
    "        min_iit_pair_examples = self.min_iit_pair_examples\n",
    "        match_non_int_type = self.match_non_int_type\n",
    "        \n",
    "        query_dataset = get_iit_examples(dev_dataset)\n",
    "        iit_pairs_dataset = []\n",
    "        iit_id = 0\n",
    "        for index, row in pairs_dataset.iterrows():\n",
    "            query_description_base = row['description_base']\n",
    "            query_int_type = row['intervention_type']\n",
    "            query_non_int_type = {\n",
    "                \"ambiance\", \"food\", \"noise\", \"service\"\n",
    "            } - {query_int_type}\n",
    "            query_int_aspect_base = row[\"intervention_aspect_base\"]\n",
    "            query_int_aspect_assignment = row['intervention_aspect_counterfactual']\n",
    "            query_original_id = row[\"original_id_base\"]\n",
    "            matched_iit_examples = query_dataset[\n",
    "                (query_dataset[f\"{query_int_type}_aspect_majority\"]==query_int_aspect_assignment)&\n",
    "                (query_dataset[\"original_id\"]!=query_original_id)\n",
    "            ]\n",
    "            if match_non_int_type:\n",
    "                for _t in query_non_int_type:\n",
    "                    matched_iit_examples = matched_iit_examples[\n",
    "                        (matched_iit_examples[f\"{_t}_aspect_majority\"]==\\\n",
    "                         row[f\"{_t}_aspect_majority_base\"])\n",
    "                    ]\n",
    "            if len(set(matched_iit_examples[\"id\"])) < min_iit_pair_examples:\n",
    "                if match_non_int_type:\n",
    "                    # simply avoid mapping the rest of the aspects.\n",
    "                    matched_iit_examples = query_dataset[\n",
    "                        (query_dataset[f\"{query_int_type}_aspect_majority\"]==query_int_aspect_assignment)&\n",
    "                        (query_dataset[\"original_id\"]!=query_original_id)\n",
    "                    ]\n",
    "                else:\n",
    "                    assert False # we need to check the number!\n",
    "            sampled_iit_example_ids = random.sample(\n",
    "                set(matched_iit_examples[\"id\"]), min_iit_pair_examples\n",
    "            )\n",
    "            for _id in sampled_iit_example_ids:\n",
    "                description_iit = query_dataset[query_dataset[\"id\"]==_id][\"description\"].iloc[0]\n",
    "                iit_pairs_dataset += [[\n",
    "                    iit_id,\n",
    "                    query_int_type,\n",
    "                    query_description_base, \n",
    "                    description_iit\n",
    "                ]]\n",
    "            iit_id += 1\n",
    "        iit_pairs_dataset = pd.DataFrame(\n",
    "            columns=[\n",
    "                'iit_id',\n",
    "                'intervention_type', \n",
    "                'description_base', \n",
    "                'description_iit'], \n",
    "            data=iit_pairs_dataset\n",
    "        )\n",
    "        \n",
    "        base_x = self.tokenizer(\n",
    "            iit_pairs_dataset['description_base'].to_list(), \n",
    "            padding=True, truncation=True, return_tensors='pt'\n",
    "        )\n",
    "        source_x = self.tokenizer(\n",
    "            iit_pairs_dataset['description_iit'].to_list(), \n",
    "            padding=True, truncation=True, return_tensors='pt'\n",
    "        )\n",
    "        intervention_corr = []\n",
    "        for _type in iit_pairs_dataset[\"intervention_type\"].tolist():\n",
    "            if _type == \"ambiance\":\n",
    "                intervention_corr += [0]\n",
    "            if _type == \"food\":\n",
    "                intervention_corr += [1]\n",
    "            if _type == \"noise\":\n",
    "                intervention_corr += [2]\n",
    "            if _type == \"service\":\n",
    "                intervention_corr += [3]\n",
    "        intervention_corr = torch.tensor(intervention_corr).long()\n",
    "        return base_x, source_x, intervention_corr, iit_pairs_dataset\n",
    "    \n",
    "    def estimate_icace(self, pairs, df):\n",
    "        CPM_iTEs = []\n",
    "        self.blackbox_model.eval()\n",
    "        self.cpm_model.model.eval()\n",
    "        base_x, source_x, intervention_corr, iit_pairs_dataset = self.preprocess(\n",
    "            pairs, df\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            for i in tqdm(range(ceil(len(iit_pairs_dataset)/self.batch_size))):\n",
    "                base_x_batch = {k:v[i*self.batch_size:(i+1)*self.batch_size].to(self.device) for k,v in base_x.items()} \n",
    "                source_x_batch = {k:v[i*self.batch_size:(i+1)*self.batch_size].to(self.device) for k,v in source_x.items()} \n",
    "                intervention_corr_batch = intervention_corr[i*self.batch_size:(i+1)*self.batch_size].to(self.device)\n",
    "                \n",
    "                base_outputs = torch.nn.functional.softmax(\n",
    "                    self.blackbox_model(**base_x_batch).logits.cpu(), dim=-1\n",
    "                ).detach()\n",
    "                _, _, counterfactual_outputs = self.cpm_model.forward(\n",
    "                    base=(base_x_batch['input_ids'], base_x_batch['attention_mask']),\n",
    "                    source=(source_x_batch['input_ids'], source_x_batch['attention_mask']),\n",
    "                    base_intervention_corr=intervention_corr_batch,\n",
    "                    source_intervention_corr=intervention_corr_batch,\n",
    "                )\n",
    "                counterfactual_outputs = torch.nn.functional.softmax(\n",
    "                    counterfactual_outputs[\"logits\"][0].cpu(), dim=-1\n",
    "                ).detach()\n",
    "                CPM_iTE = counterfactual_outputs-base_outputs\n",
    "                CPM_iTEs.append(CPM_iTE)\n",
    "        CPM_iTEs = torch.concat(CPM_iTEs)\n",
    "        CPM_iTEs = np.round(CPM_iTEs.numpy(), decimals=4)\n",
    "\n",
    "        # only for iit explainer!\n",
    "        iit_pairs_dataset[\"EiCaCE\"] = list(CPM_iTEs)\n",
    "        CPM_iTEs = list(iit_pairs_dataset.groupby([\"iit_id\"])[\"EiCaCE\"].mean())\n",
    "        \n",
    "        return CPM_iTEs\n",
    "\n",
    "def cebab_pipeline(\n",
    "    model, explainer, \n",
    "    train_dataset, dev_dataset, \n",
    "    dataset_type='5-way', \n",
    "    shorten_model_name=False,\n",
    "    correction_epsilon=0.001,\n",
    "):\n",
    "    # get predictions on train and dev\n",
    "    train_predictions, _ = model.predict_proba(\n",
    "        train_dataset\n",
    "    )\n",
    "    dev_predictions, dev_report = model.predict_proba(\n",
    "        dev_dataset\n",
    "    )\n",
    "\n",
    "    # append predictions to datasets\n",
    "    train_dataset['prediction'] = list(train_predictions)\n",
    "    dev_dataset['prediction'] = list(dev_predictions)\n",
    "\n",
    "    # fit explainer\n",
    "    explainer.fit(\n",
    "        train_dataset, train_predictions, \n",
    "        model, dev_dataset\n",
    "    )\n",
    "\n",
    "    # get intervention pairs\n",
    "    \n",
    "    pairs_dataset = get_intervention_pairs(\n",
    "        dev_dataset, dataset_type=dataset_type\n",
    "    )  # TODO why is the index not unique here?\n",
    "        \n",
    "    # get explanations\n",
    "    if isinstance(explanator, CausalProxyModel):\n",
    "        explanations = explainer.estimate_icace(\n",
    "            pairs_dataset,\n",
    "            train_dataset # for query data.\n",
    "        )\n",
    "    else:\n",
    "        explanations = explainer.estimate_icace(\n",
    "            pairs_dataset,\n",
    "        )\n",
    "    \n",
    "    # append explanations to the pairs\n",
    "    pairs_dataset['EICaCE'] = explanations\n",
    "    \n",
    "    # TODO: add cosine\n",
    "    pairs_dataset = metric_utils._calculate_ite(pairs_dataset)  # effect of crowd-workers on other crowd-workers (no model, no explainer)\n",
    "    \n",
    "    def _calculate_icace(pairs):\n",
    "        \"\"\"\n",
    "        This metric measures the effect of a certain concept on the given model.\n",
    "        It is independent of the explainer.\n",
    "        \"\"\"\n",
    "        pairs['ICaCE'] = (pairs['prediction_counterfactual'] - pairs['prediction_base']).apply(lambda x: np.round(x, decimals=4))\n",
    "\n",
    "        return pairs\n",
    "    pairs_dataset = _calculate_icace(pairs_dataset)  # effect of concept on the model (with model, no explainer)\n",
    "    \n",
    "    # TOREMOVE: just to try if we ignore all [0,0,...] cases here.\n",
    "    # zeros_like = tuple([0.0 for i in range(int(dataset_type.split(\"-\")[0]))])\n",
    "    # pairs_dataset = pairs_dataset[pairs_dataset.ICaCE.map(tuple).isin([zeros_like])==False]\n",
    "    \n",
    "    def _cosine_distance(a,b,epsilon):\n",
    "        if epsilon == None:\n",
    "            if np.linalg.norm(a, ord=2) == 0 or np.linalg.norm(b, ord=2) == 0:\n",
    "                return 1\n",
    "            else:\n",
    "                return cosine(a,b)\n",
    "        \n",
    "        if np.linalg.norm(a, ord=2) == 0 and np.linalg.norm(b, ord=2) == 0:\n",
    "            \"\"\"\n",
    "            We cannot determine whether prediction is corrected or not.\n",
    "            Thus, we simply return 1.\n",
    "            \"\"\"\n",
    "            return 1\n",
    "        elif np.linalg.norm(a, ord=2) == 0:\n",
    "            \"\"\"\n",
    "            When true iCACE score is 0, instead of always returning 1, we\n",
    "            allow some epsilon error by default. If the EiCACE is within a\n",
    "            range, we return the error as 0.\n",
    "            \"\"\"\n",
    "            if np.max(np.abs(b)) <= epsilon:\n",
    "                return 0\n",
    "            else:\n",
    "                return 1\n",
    "        elif np.linalg.norm(b, ord=2) == 0:\n",
    "            \"\"\"\n",
    "            This case happens when iCACE is not 0, but EiCACE is 0. This is\n",
    "            unlikely, but we give score of 1 for this case.\n",
    "            \"\"\"\n",
    "            return 1\n",
    "        else:\n",
    "            return cosine(a,b)\n",
    "    \n",
    "    def _calculate_estimate_loss(pairs,epsilon):\n",
    "        \"\"\"\n",
    "        Calculate the distance between the ICaCE and EICaCE.\n",
    "        \"\"\"\n",
    "\n",
    "        pairs['ICaCE-L2'] = pairs[['ICaCE', 'EICaCE']].apply(lambda x: np.linalg.norm(x[0] - x[1], ord=2), axis=1)\n",
    "        pairs['ICaCE-cosine'] = pairs[['ICaCE', 'EICaCE']].apply(lambda x: _cosine_distance(x[0], x[1], epsilon), axis=1)\n",
    "        pairs['ICaCE-normdiff'] = pairs[['ICaCE', 'EICaCE']].apply(lambda x: abs(np.linalg.norm(x[0], ord=2) - np.linalg.norm(x[1], ord=2)), axis=1)\n",
    "\n",
    "        return pairs\n",
    "    \n",
    "    pairs_dataset = _calculate_estimate_loss(pairs_dataset,correction_epsilon)  # l2 CEBaB Score (model and explainer)\n",
    "\n",
    "    # only keep columns relevant for metrics\n",
    "    CEBaB_metrics_per_pair = pairs_dataset[[\n",
    "        'intervention_type', 'intervention_aspect_base', 'intervention_aspect_counterfactual', 'ITE', 'ICaCE', 'EICaCE', 'ICaCE-L2', 'ICaCE-cosine', 'ICaCE-normdiff']].copy()\n",
    "    CEBaB_metrics_per_pair['count'] = 1\n",
    "\n",
    "    # get CEBaB tables\n",
    "    metrics = ['count', 'ICaCE', 'EICaCE']\n",
    "\n",
    "    groupby_aspect_direction = ['intervention_type', 'intervention_aspect_base', 'intervention_aspect_counterfactual']\n",
    "\n",
    "    CaCE_per_aspect_direction = metric_utils._aggregate_metrics(CEBaB_metrics_per_pair, groupby_aspect_direction, metrics)\n",
    "    CaCE_per_aspect_direction.columns = ['count', 'CaCE', 'ECaCE']\n",
    "    CaCE_per_aspect_direction = CaCE_per_aspect_direction.set_index(['count'], append=True)\n",
    "    \n",
    "    ACaCE_per_aspect = metric_utils._aggregate_metrics(CaCE_per_aspect_direction.abs(), ['intervention_type'], ['CaCE', 'ECaCE'])\n",
    "    ACaCE_per_aspect.columns = ['ACaCE', 'EACaCE']\n",
    "\n",
    "    CEBaB_metrics_per_aspect_direction = metric_utils._aggregate_metrics(CEBaB_metrics_per_pair, groupby_aspect_direction, ['count', 'ICaCE-L2', 'ICaCE-cosine', 'ICaCE-normdiff'])\n",
    "    CEBaB_metrics_per_aspect_direction.columns = ['count', 'ICaCE-L2', 'ICaCE-cosine', 'ICaCE-normdiff']\n",
    "    CEBaB_metrics_per_aspect_direction = CEBaB_metrics_per_aspect_direction.set_index(['count'], append=True)\n",
    "\n",
    "    CEBaB_metrics_per_aspect = metric_utils._aggregate_metrics(CEBaB_metrics_per_pair, ['intervention_type'], ['count', 'ICaCE-L2', 'ICaCE-cosine', 'ICaCE-normdiff'])\n",
    "    CEBaB_metrics_per_aspect.columns = ['count', 'ICaCE-L2', 'ICaCE-cosine', 'ICaCE-normdiff']\n",
    "    CEBaB_metrics_per_aspect = CEBaB_metrics_per_aspect.set_index(['count'], append=True)\n",
    "\n",
    "    CEBaB_metrics = metric_utils._aggregate_metrics(CEBaB_metrics_per_pair, [], ['ICaCE-L2', 'ICaCE-cosine', 'ICaCE-normdiff'])\n",
    "\n",
    "    # get ATE table\n",
    "    ATE = metric_utils._aggregate_metrics(CEBaB_metrics_per_pair, groupby_aspect_direction, ['count', 'ITE'])\n",
    "    ATE.columns = ['count', 'ATE']\n",
    "\n",
    "    # add model and explainer information\n",
    "    if shorten_model_name:\n",
    "        model_name = str(model).split('.')[0]\n",
    "    else:\n",
    "        model_name = str(model)\n",
    "\n",
    "    CaCE_per_aspect_direction.columns = pd.MultiIndex.from_tuples(\n",
    "        [(model_name, str(explainer), col) if col != 'CaCE' else (model_name, '', col) for col in CaCE_per_aspect_direction.columns])\n",
    "    ACaCE_per_aspect.columns = pd.MultiIndex.from_tuples(\n",
    "        [(model_name, str(explainer), col) if col != 'ACaCE' else (model_name, '', col) for col in ACaCE_per_aspect.columns])\n",
    "    CEBaB_metrics_per_aspect_direction.columns = pd.MultiIndex.from_tuples(\n",
    "        [(model_name, str(explainer), col) for col in CEBaB_metrics_per_aspect_direction.columns])\n",
    "    CEBaB_metrics_per_aspect.columns = pd.MultiIndex.from_tuples(\n",
    "        [(model_name, str(explainer), col) for col in CEBaB_metrics_per_aspect.columns])\n",
    "    CEBaB_metrics.index = pd.MultiIndex.from_product([[model_name], [str(explainer)], CEBaB_metrics.index])\n",
    "    \n",
    "    # performance report\n",
    "    performance_report_index = ['macro-f1', 'accuracy']\n",
    "    performance_report_data = [dev_report['macro avg']['f1-score'], dev_report['accuracy']]\n",
    "    performance_report_col = [model_name]\n",
    "    performance_report = pd.DataFrame(data=performance_report_data, index=performance_report_index, columns=performance_report_col)\n",
    "\n",
    "    return pairs_dataset, ATE, CEBaB_metrics, CEBaB_metrics_per_aspect_direction, CEBaB_metrics_per_aspect, CaCE_per_aspect_direction, ACaCE_per_aspect, performance_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main evaluate script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The following blocks will run CEBaB benchmark in\n",
    "all the combinations of the following conditions.\n",
    "\"\"\"\n",
    "grid = {\n",
    "    \"h_dim\": [192],\n",
    "    \"class_num\": [5],\n",
    "    \"control\": [False],\n",
    "    \"beta\" : [1.0],\n",
    "    \"gemma\" : [3.0],\n",
    "    \"cls_dropout\" : [0.1],\n",
    "    \"enc_dropout\" : [0.1],\n",
    "    \"model_arch\" : [\"bert-base-uncased\"]\n",
    "}\n",
    "\n",
    "keys, values = zip(*grid.items())\n",
    "permutations_dicts = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "device = 'cuda:9'\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for this setting:  (('seed', 42), ('class_num', 5), ('beta', 1.0), ('gemma', 3.0), ('h_dim', 192), ('dataset_type', '5-way'), ('correction_epsilon', None), ('cls_dropout', 0.1), ('enc_dropout', 0.1), ('control', False), ('model_arch', 'bert-base-uncased'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration CEBaB--CEBaB-0e2f7ed67c9d7e55\n",
      "Reusing dataset parquet (../../huggingface_cache/parquet/CEBaB--CEBaB-0e2f7ed67c9d7e55/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54331d9a577e4ab69a827454c929c97f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping no majority reviews: 16.03% of train dataset.\n",
      "intervention_h_dim=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:26<00:00,  4.65it/s]\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for i in range(len(permutations_dicts)):\n",
    "    \n",
    "    seed=42\n",
    "    class_num=permutations_dicts[i][\"class_num\"]\n",
    "    beta=permutations_dicts[i][\"beta\"]\n",
    "    gemma=permutations_dicts[i][\"gemma\"]\n",
    "    h_dim=permutations_dicts[i][\"h_dim\"]\n",
    "    dataset_type = f'{class_num}-way'\n",
    "    correction_epsilon=None\n",
    "    cls_dropout=permutations_dicts[i][\"cls_dropout\"]\n",
    "    enc_dropout=permutations_dicts[i][\"enc_dropout\"]\n",
    "    control=permutations_dicts[i][\"control\"]\n",
    "    model_arch=permutations_dicts[i][\"model_arch\"]\n",
    "    \n",
    "    if model_arch == \"bert-base-uncased\":\n",
    "        model_path = \"BERT-control-results\" if control else \"BERT-results\"\n",
    "        model_module = BERTForCEBaB\n",
    "        explainer_module = CausalProxyModelForBERT\n",
    "    elif model_arch == \"roberta-base\":\n",
    "        model_path = \"RoBERTa-control-results\" if control else \"RoBERTa-results\"\n",
    "    elif model_arch == \"gpt2\":\n",
    "        model_path = \"gpt2-control-results\" if control else \"gpt2-results\"\n",
    "    elif model_arch == \"lstm\":\n",
    "        model_path = \"lstm-control-results\" if control else \"lstm-results\"\n",
    "        \n",
    "    grid_conditions=(\n",
    "        (\"seed\", seed),\n",
    "        (\"class_num\", class_num),\n",
    "        (\"beta\", beta),\n",
    "        (\"gemma\", gemma),\n",
    "        (\"h_dim\", h_dim),\n",
    "        (\"dataset_type\", dataset_type),\n",
    "        (\"correction_epsilon\", correction_epsilon),\n",
    "        (\"cls_dropout\", cls_dropout),\n",
    "        (\"enc_dropout\", enc_dropout),\n",
    "        (\"control\", control),\n",
    "        (\"model_arch\", model_arch),\n",
    "    )\n",
    "    print(\"Running for this setting: \", grid_conditions)\n",
    "\n",
    "    blackbox_model_path = f'CEBaB/{model_arch}.CEBaB.sa.{class_num}-class.exclusive.seed_{seed}'\n",
    "    if control:\n",
    "        cpm_model_path = blackbox_model_path\n",
    "    else:\n",
    "        cpm_model_path = f'../proxy_training_results/{model_path}/'\\\n",
    "                           f'cebab.train.train.alpha.1.0'\\\n",
    "                           f'.beta.{beta}.gemma.{gemma}.dim.{h_dim}.hightype.'\\\n",
    "                           f'{model_arch}.Proxy.'\\\n",
    "                           f'CEBaB.sa.{class_num}-class.exclusive.'\\\n",
    "                           f'mode.align.cls.dropout.{cls_dropout}.enc.dropout.{enc_dropout}.seed_{seed}'\n",
    "\n",
    "    # load data from HF\n",
    "    cebab = datasets.load_dataset(\n",
    "        'CEBaB/CEBaB', use_auth_token=True,\n",
    "        cache_dir=\"../../huggingface_cache/\"\n",
    "    )\n",
    "    cebab['train'] = cebab['train_exclusive']\n",
    "    train, dev, test = preprocess_hf_dataset(\n",
    "        cebab, one_example_per_world=False, \n",
    "        verbose=1, dataset_type=dataset_type\n",
    "    )\n",
    "\n",
    "    tf_model = model_module(\n",
    "        blackbox_model_path, \n",
    "        device=device, \n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    explanator = explainer_module(\n",
    "        blackbox_model_path,\n",
    "        cpm_model_path, \n",
    "        device=device, \n",
    "        batch_size=batch_size,\n",
    "        intervention_h_dim=h_dim,\n",
    "    )\n",
    "\n",
    "    train_dataset = train.copy()\n",
    "    dev_dataset = test.copy()\n",
    "\n",
    "    result_per_example, ATE, CEBaB_metrics, CEBaB_metrics_per_aspect_direction, \\\n",
    "    CEBaB_metrics_per_aspect, CaCE_per_aspect_direction, \\\n",
    "    ACaCE_per_aspect, performance_report = cebab_pipeline(\n",
    "        tf_model, explanator, \n",
    "        train_dataset, dev_dataset, \n",
    "        dataset_type=dataset_type,\n",
    "        correction_epsilon=correction_epsilon,\n",
    "    )\n",
    "    \n",
    "    results[grid_conditions] = (\n",
    "        result_per_example, ATE, CEBaB_metrics, CEBaB_metrics_per_aspect_direction, \\\n",
    "        CEBaB_metrics_per_aspect, CaCE_per_aspect_direction, \\\n",
    "        ACaCE_per_aspect, performance_report\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabularize your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h_dim</th>\n",
       "      <th>class_num</th>\n",
       "      <th>control</th>\n",
       "      <th>beta</th>\n",
       "      <th>gemma</th>\n",
       "      <th>cls_dropout</th>\n",
       "      <th>enc_dropout</th>\n",
       "      <th>model_arch</th>\n",
       "      <th>ICaCE-L2</th>\n",
       "      <th>ICaCE-cosine</th>\n",
       "      <th>ICaCE-normdiff</th>\n",
       "      <th>macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>0.6617</td>\n",
       "      <td>0.4717</td>\n",
       "      <td>0.4691</td>\n",
       "      <td>0.696461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   h_dim  class_num  control  beta  gemma  cls_dropout  enc_dropout  \\\n",
       "0    192          5    False   1.0    3.0          0.1          0.1   \n",
       "\n",
       "          model_arch  ICaCE-L2  ICaCE-cosine  ICaCE-normdiff  macro-f1  \n",
       "0  bert-base-uncased    0.6617        0.4717          0.4691  0.696461  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_keys = list(grid.keys())\n",
    "values = []\n",
    "for k, v in results.items():\n",
    "    _values = []\n",
    "    for ik in important_keys:\n",
    "        _values.append(dict(k)[ik])\n",
    "    _values.append(v[2][\"ICaCE-L2\"].iloc[0])\n",
    "    _values.append(v[2][\"ICaCE-cosine\"].iloc[0])\n",
    "    _values.append(v[2][\"ICaCE-normdiff\"].iloc[0])\n",
    "    _values.append(v[-1].iloc[0][0])\n",
    "    values.append(_values)\n",
    "important_keys.extend([\"ICaCE-L2\", \"ICaCE-cosine\", \"ICaCE-normdiff\", \"macro-f1\"])\n",
    "df = pd.DataFrame(values, columns=important_keys)\n",
    "df.sort_values(by=['class_num'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk import edit_distance\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, GroupShuffleSplit\n",
    "import datasets\n",
    "from datasets import Dataset, DatasetDict\n",
    "from functools import reduce\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_json(\"../OpenTable/mturk/dataset/dataset-2022-02-24-train.json\")\n",
    "dev_df = pd.read_json(\"../OpenTable/mturk/dataset/dataset-2022-02-24-dev.json\")\n",
    "test_df = pd.read_json(\"../OpenTable/mturk/dataset/dataset-2022-02-24-test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_absa_labels_df(\n",
    "    df,\n",
    "    aspect_label_encode={\n",
    "        \"Negative\":0,\n",
    "        \"Positive\":1,\n",
    "        \"unknown\":2,\n",
    "        \"no majority\": 2,\n",
    "    },\n",
    "    sequence_label_encode={\n",
    "        \"5\": 4,\n",
    "        \"4\": 3,\n",
    "        \"3\": 2,\n",
    "        \"2\": 1,\n",
    "        \"1\": 0,\n",
    "        \"no majority\": -1, # will be dropped!\n",
    "    },\n",
    "):\n",
    "    train_df = df.copy()\n",
    "    train_df['group_id'] = train_df['original_description'].apply(hash)\n",
    "    train_df['group_id'] = train_df['group_id'].rank(method='dense', ascending=False).astype(int)\n",
    "    \n",
    "    original_train_df = train_df[\n",
    "        [\n",
    "            'group_id',\n",
    "            'original_description', \n",
    "            'type', \n",
    "            'original_majority', \n",
    "            'original_review_majority' \n",
    "        ]\n",
    "    ].rename(\n",
    "        columns={\n",
    "            'original_description': 'text', \n",
    "            'type': 'aspect', \n",
    "            'original_majority': 'aspect_label',\n",
    "            'original_review_majority': 'sentence_label'\n",
    "        }\n",
    "    )\n",
    "    original_train_df[\"original\"] = True\n",
    "    \n",
    "    edit_train_df = train_df[\n",
    "        [\n",
    "            'group_id',\n",
    "            'edit_description', \n",
    "            'type', \n",
    "            'edit_majority', \n",
    "            'edit_review_majority' \n",
    "        ]\n",
    "    ].rename(\n",
    "        columns={\n",
    "            'edit_description': 'text', \n",
    "            'type': 'aspect', \n",
    "            'edit_majority': 'aspect_label',\n",
    "            'edit_review_majority': 'sentence_label'\n",
    "        }\n",
    "    )\n",
    "    edit_train_df[\"original\"] = False\n",
    "\n",
    "    original_train_df = original_train_df.replace(\n",
    "        {\n",
    "            \"aspect_label\": aspect_label_encode, \n",
    "            \"sentence_label\": sequence_label_encode\n",
    "        }\n",
    "    ).drop_duplicates()\n",
    "    edit_train_df = edit_train_df.replace(\n",
    "        {\n",
    "            \"aspect_label\": aspect_label_encode, \n",
    "            \"sentence_label\": sequence_label_encode\n",
    "        }\n",
    "    ).drop_duplicates()\n",
    "    \n",
    "    original_train_df = original_train_df.reset_index(drop=True)\n",
    "    edit_train_df = edit_train_df.reset_index(drop=True)\n",
    "    \n",
    "    pivot_original_train_df = pd.pivot_table(\n",
    "        original_train_df,\n",
    "        values='aspect_label',\n",
    "        columns='aspect',\n",
    "        index=['text', 'sentence_label', 'group_id', 'original'],\n",
    "    )\n",
    "    pivot_original_train_df.reset_index(inplace=True)\n",
    "    pivot_original_train_df.columns = [\n",
    "        \"text\", \"label\", \"group_id\", \"original\",\n",
    "        \"ambiance_label\", \"food_label\", \"noise_label\", \"service_label\"\n",
    "    ]\n",
    "\n",
    "    pivot_edit_train_df = pd.pivot_table(\n",
    "        edit_train_df,\n",
    "        values='aspect_label',\n",
    "        columns='aspect',\n",
    "        index=['text', 'sentence_label', 'group_id', 'original'],\n",
    "    )\n",
    "    pivot_edit_train_df.reset_index(inplace=True)\n",
    "    pivot_edit_train_df.columns = [\n",
    "        \"text\", \"label\", \"group_id\", \"original\",\n",
    "        \"ambiance_label\", \"food_label\", \"noise_label\", \"service_label\"\n",
    "    ]\n",
    "    \n",
    "#     for aspect_label in [\"ambiance_label\", \"food_label\", \"noise_label\", \"service_label\"]:\n",
    "#         pivot_edit_train_df[aspect_label] = np.where(\n",
    "#             pivot_edit_train_df[aspect_label].isnull(),\n",
    "#             pivot_edit_train_df['group_id'].map(\n",
    "#                 pivot_original_train_df.set_index('group_id')[aspect_label]\n",
    "#             ),\n",
    "#             pivot_edit_train_df[aspect_label]\n",
    "#         )\n",
    "#         pivot_edit_train_df[aspect_label] = pivot_edit_train_df[aspect_label].astype(int)\n",
    "    \n",
    "    pivot_train_df = pd.concat((pivot_original_train_df, pivot_edit_train_df))\n",
    "    pivot_train_df = pivot_train_df[(pivot_train_df[\"label\"]!=-1)].drop_duplicates(subset='text')\n",
    "    pivot_train_df.reset_index(drop=True, inplace=True)\n",
    "    pivot_train_df = pivot_train_df.fillna(-1)\n",
    "    for aspect_label in [\"ambiance_label\", \"food_label\", \"noise_label\", \"service_label\"]:\n",
    "        pivot_train_df[aspect_label] = pivot_train_df[aspect_label].astype(int)\n",
    "    \n",
    "    ood_train_df = []\n",
    "    for aspect_label in [\"ambiance_label\", \"food_label\", \"noise_label\", \"service_label\"]:\n",
    "\n",
    "        ood_0 = pivot_train_df[\n",
    "            (pivot_train_df[aspect_label]==1) &\n",
    "            (pivot_train_df[\"label\"]==0)\n",
    "        ]\n",
    "\n",
    "        ood_1 = pivot_train_df[\n",
    "            (pivot_train_df[aspect_label]==1) &\n",
    "            (pivot_train_df[\"label\"]==1)\n",
    "        ]\n",
    "\n",
    "        ood_3 = pivot_train_df[\n",
    "            (pivot_train_df[aspect_label]==0) &\n",
    "            (pivot_train_df[\"label\"]==3)\n",
    "        ]\n",
    "\n",
    "        ood_4 = pivot_train_df[\n",
    "            (pivot_train_df[aspect_label]==0) &\n",
    "            (pivot_train_df[\"label\"]==4)\n",
    "        ]\n",
    "\n",
    "        ood_train_df += [pd.concat(\n",
    "            (ood_0, ood_1, ood_3, ood_4)\n",
    "        )]\n",
    "    ood_train_df = pd.concat(ood_train_df).drop_duplicates()\n",
    "    \n",
    "    iid_train_df = pivot_train_df.iloc[\n",
    "        pivot_train_df.index.difference(\n",
    "            ood_train_df.index\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    return iid_train_df, ood_train_df, pivot_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "seed=7\n",
    "iid_train_df, ood_train_df, all_train_df = get_absa_labels_df(train_df)\n",
    "if k > 0:\n",
    "    if k >= len(ood_train_df):\n",
    "        k = len(ood_train_df)\n",
    "        k_shots_train = ood_train_df\n",
    "    else:\n",
    "        _, k_shots_train = train_test_split(\n",
    "            ood_train_df, test_size=k, random_state=seed\n",
    "        )\n",
    "    iid_train_df = pd.concat((\n",
    "        iid_train_df, \n",
    "        k_shots_train, \n",
    "    ))\n",
    "\n",
    "iid_dev_df, ood_dev_df, all_dev_df = get_absa_labels_df(\n",
    "    dev_df,\n",
    "    sequence_label_encode={\n",
    "        5: 4,\n",
    "        4: 3,\n",
    "        3: 2,\n",
    "        2: 1,\n",
    "        1: 0,\n",
    "    }\n",
    ")\n",
    "iid_test_df, ood_test_df, all_test_df = get_absa_labels_df(\n",
    "    test_df,\n",
    "    sequence_label_encode={\n",
    "        5: 4,\n",
    "        4: 3,\n",
    "        3: 2,\n",
    "        2: 1,\n",
    "        1: 0,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "iid_train_df = Dataset.from_pandas(iid_train_df)\n",
    "\n",
    "all_dev_df = Dataset.from_pandas(all_dev_df)\n",
    "ood_dev_df = Dataset.from_pandas(ood_dev_df)\n",
    "iid_dev_df = Dataset.from_pandas(iid_dev_df)\n",
    "\n",
    "all_test_df = Dataset.from_pandas(all_test_df)\n",
    "ood_test_df = Dataset.from_pandas(ood_test_df)\n",
    "iid_test_df = Dataset.from_pandas(iid_test_df)\n",
    "\n",
    "opentable_seq_cls_dataset = DatasetDict()\n",
    "opentable_seq_cls_dataset['train'] = iid_train_df\n",
    "\n",
    "opentable_seq_cls_dataset['validation'] = all_dev_df\n",
    "opentable_seq_cls_dataset['validation_ood'] = ood_dev_df\n",
    "opentable_seq_cls_dataset['validation_iid'] = iid_dev_df\n",
    "\n",
    "opentable_seq_cls_dataset['test'] = all_test_df\n",
    "opentable_seq_cls_dataset['test_ood'] = ood_test_df\n",
    "opentable_seq_cls_dataset['test_iid'] = iid_test_df\n",
    "\n",
    "opentable_seq_cls_dataset.save_to_disk(f\"./datasets/sequence_classification_ood.k_{k}.seed_{seed}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'group_id', 'original', 'ambiance_label', 'food_label', 'noise_label', 'service_label', '__index_level_0__'],\n",
       "        num_rows: 8469\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'group_id', 'original', 'ambiance_label', 'food_label', 'noise_label', 'service_label'],\n",
       "        num_rows: 1660\n",
       "    })\n",
       "    validation_ood: Dataset({\n",
       "        features: ['text', 'label', 'group_id', 'original', 'ambiance_label', 'food_label', 'noise_label', 'service_label', '__index_level_0__'],\n",
       "        num_rows: 222\n",
       "    })\n",
       "    validation_iid: Dataset({\n",
       "        features: ['text', 'label', 'group_id', 'original', 'ambiance_label', 'food_label', 'noise_label', 'service_label', '__index_level_0__'],\n",
       "        num_rows: 1438\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'group_id', 'original', 'ambiance_label', 'food_label', 'noise_label', 'service_label'],\n",
       "        num_rows: 1678\n",
       "    })\n",
       "    test_ood: Dataset({\n",
       "        features: ['text', 'label', 'group_id', 'original', 'ambiance_label', 'food_label', 'noise_label', 'service_label', '__index_level_0__'],\n",
       "        num_rows: 219\n",
       "    })\n",
       "    test_iid: Dataset({\n",
       "        features: ['text', 'label', 'group_id', 'original', 'ambiance_label', 'food_label', 'noise_label', 'service_label', '__index_level_0__'],\n",
       "        num_rows: 1459\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opentable_seq_cls_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk import edit_distance\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, GroupShuffleSplit\n",
    "import datasets\n",
    "from datasets import Dataset, DatasetDict\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import os \n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split_new_scheme(splitname):\n",
    "    filename = os.path.join(\"../OpenTable/mturk/dataset\", f\"dataset-2022-05-09-{splitname}.json\")\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "    for d in data:\n",
    "        for k, v in d.items():\n",
    "            if isinstance(v, dict):\n",
    "                d[k] = json.dumps(v)\n",
    "    return data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(load_split_new_scheme(\"train\"))\n",
    "dev = pd.DataFrame(load_split_new_scheme(\"dev\"))\n",
    "test = pd.DataFrame(load_split_new_scheme(\"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(\n",
    "    df_in,\n",
    "    aspect_label_encode={\n",
    "        \"Negative\":0,\n",
    "        \"Positive\":1,\n",
    "        \"unknown\":2,\n",
    "        \"no majority\": 2,\n",
    "    },\n",
    "    sequence_label_encode={\n",
    "        \"5\": 1,\n",
    "        \"4\": 1,\n",
    "        \"3\": -1,\n",
    "        \"2\": 0,\n",
    "        \"1\": 0,\n",
    "        \"no majority\": -1, # will be dropped!\n",
    "    },\n",
    "    \n",
    "):\n",
    "    df = df_in.copy()\n",
    "    columns_to_keep = [\n",
    "        'id', 'original_id', 'edit_id', 'is_original', \n",
    "        'description', 'review_majority',\n",
    "        'food_aspect_majority', 'ambiance_aspect_majority', \n",
    "        'service_aspect_majority', 'noise_aspect_majority'\n",
    "    ]\n",
    "    columns_to_keep += [col for col in df.columns if 'prediction' in col]\n",
    "    df = df[df[\"review_majority\"]!=\"no majority\"]\n",
    "    df = df[columns_to_keep].rename(\n",
    "        columns={\n",
    "            'description': 'text', \n",
    "            'review_majority': 'label',\n",
    "            'food_aspect_majority': 'food_label',\n",
    "            'ambiance_aspect_majority': 'ambiance_label',\n",
    "            'service_aspect_majority': 'service_label',\n",
    "            'noise_aspect_majority': 'noise_label'\n",
    "        }\n",
    "    )\n",
    "    df = df.replace(\"\", -1).replace(\n",
    "        {\n",
    "            \"label\": sequence_label_encode, \n",
    "            \"food_label\": aspect_label_encode,\n",
    "            \"ambiance_label\": aspect_label_encode,\n",
    "            \"service_label\": aspect_label_encode,\n",
    "            \"noise_label\": aspect_label_encode\n",
    "        }\n",
    "    )\n",
    "    df = df[df[\"label\"]!=-1]\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_train = Dataset.from_pandas(process_df(train))\n",
    "post_dev = Dataset.from_pandas(process_df(dev))\n",
    "post_test = Dataset.from_pandas(process_df(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "opentable_seq_cls_dataset = DatasetDict()\n",
    "opentable_seq_cls_dataset['train'] = post_train\n",
    "opentable_seq_cls_dataset['validation'] = post_dev\n",
    "opentable_seq_cls_dataset['test'] = post_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'original_id', 'edit_id', 'is_original', 'text', 'label', 'food_label', 'ambiance_label', 'service_label', 'noise_label', '__index_level_0__'],\n",
       "        num_rows: 1072\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'original_id', 'edit_id', 'is_original', 'text', 'label', 'food_label', 'ambiance_label', 'service_label', 'noise_label', '__index_level_0__'],\n",
       "        num_rows: 1221\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'original_id', 'edit_id', 'is_original', 'text', 'label', 'food_label', 'ambiance_label', 'service_label', 'noise_label', '__index_level_0__'],\n",
       "        num_rows: 1228\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opentable_seq_cls_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "opentable_seq_cls_dataset.save_to_disk(f\"./datasets/Proxy.CEBaB.sa.2-class.exclusive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deprecated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_absa_labels_df(\n",
    "    df,\n",
    "    aspect_label_encode={\n",
    "        \"Negative\":0,\n",
    "        \"Positive\":1,\n",
    "        \"unknown\":2,\n",
    "        \"no majority\": 2,\n",
    "    },\n",
    "    sequence_label_encode={\n",
    "        \"5\": 4,\n",
    "        \"4\": 3,\n",
    "        \"3\": 2,\n",
    "        \"2\": 1,\n",
    "        \"1\": 0,\n",
    "        \"no majority\": -1, # will be dropped!\n",
    "    },\n",
    "):\n",
    "    train_df = df.copy()\n",
    "    train_df['group_id'] = train_df['original_description'].apply(hash)\n",
    "    train_df['group_id'] = train_df['group_id'].rank(method='dense', ascending=False).astype(int)\n",
    "    \n",
    "    original_train_df = train_df[\n",
    "        [\n",
    "            'group_id',\n",
    "            'original_description', \n",
    "            'type', \n",
    "            'original_majority', \n",
    "            'original_review_majority' \n",
    "        ]\n",
    "    ].rename(\n",
    "        columns={\n",
    "            'original_description': 'text', \n",
    "            'type': 'aspect', \n",
    "            'original_majority': 'aspect_label',\n",
    "            'original_review_majority': 'sentence_label'\n",
    "        }\n",
    "    )\n",
    "    original_train_df[\"original\"] = True\n",
    "    \n",
    "    edit_train_df = train_df[\n",
    "        [\n",
    "            'group_id',\n",
    "            'edit_description', \n",
    "            'type', \n",
    "            'edit_majority', \n",
    "            'edit_review_majority' \n",
    "        ]\n",
    "    ].rename(\n",
    "        columns={\n",
    "            'edit_description': 'text', \n",
    "            'type': 'aspect', \n",
    "            'edit_majority': 'aspect_label',\n",
    "            'edit_review_majority': 'sentence_label'\n",
    "        }\n",
    "    )\n",
    "    edit_train_df[\"original\"] = False\n",
    "\n",
    "    original_train_df = original_train_df.replace(\n",
    "        {\n",
    "            \"aspect_label\": aspect_label_encode, \n",
    "            \"sentence_label\": sequence_label_encode\n",
    "        }\n",
    "    ).drop_duplicates()\n",
    "    edit_train_df = edit_train_df.replace(\n",
    "        {\n",
    "            \"aspect_label\": aspect_label_encode, \n",
    "            \"sentence_label\": sequence_label_encode\n",
    "        }\n",
    "    ).drop_duplicates()\n",
    "    \n",
    "    original_train_df = original_train_df.reset_index(drop=True)\n",
    "    edit_train_df = edit_train_df.reset_index(drop=True)\n",
    "    \n",
    "    pivot_original_train_df = pd.pivot_table(\n",
    "        original_train_df,\n",
    "        values='aspect_label',\n",
    "        columns='aspect',\n",
    "        index=['text', 'sentence_label', 'group_id', 'original'],\n",
    "    )\n",
    "    pivot_original_train_df.reset_index(inplace=True)\n",
    "    pivot_original_train_df.columns = [\n",
    "        \"text\", \"label\", \"group_id\", \"original\",\n",
    "        \"ambiance_label\", \"food_label\", \"noise_label\", \"service_label\"\n",
    "    ]\n",
    "\n",
    "    pivot_edit_train_df = pd.pivot_table(\n",
    "        edit_train_df,\n",
    "        values='aspect_label',\n",
    "        columns='aspect',\n",
    "        index=['text', 'sentence_label', 'group_id', 'original'],\n",
    "    )\n",
    "    pivot_edit_train_df.reset_index(inplace=True)\n",
    "    pivot_edit_train_df.columns = [\n",
    "        \"text\", \"label\", \"group_id\", \"original\",\n",
    "        \"ambiance_label\", \"food_label\", \"noise_label\", \"service_label\"\n",
    "    ]\n",
    "    \n",
    "    # fill aspect labels with the labels from the original ones\n",
    "    pivot_original_train_df = pivot_original_train_df.fillna(-1)\n",
    "    for aspect_label in [\"ambiance_label\", \"food_label\", \"noise_label\", \"service_label\"]:\n",
    "        pivot_edit_train_df[aspect_label] = np.where(\n",
    "            pivot_edit_train_df[aspect_label].isnull(),\n",
    "            pivot_edit_train_df['group_id'].map(\n",
    "                pivot_original_train_df.set_index('group_id')[aspect_label]\n",
    "            ),\n",
    "            pivot_edit_train_df[aspect_label]\n",
    "        )\n",
    "        pivot_edit_train_df[aspect_label] = pivot_edit_train_df[aspect_label].astype(int)\n",
    "    \n",
    "    pivot_train_df = pd.concat((pivot_original_train_df, pivot_edit_train_df))\n",
    "    pivot_train_df = pivot_train_df[(pivot_train_df[\"label\"]!=-1)].drop_duplicates(subset='text')\n",
    "    pivot_train_df.reset_index(drop=True, inplace=True)\n",
    "    pivot_train_df = pivot_train_df.fillna(-1)\n",
    "    for aspect_label in [\"ambiance_label\", \"food_label\", \"noise_label\", \"service_label\"]:\n",
    "        pivot_train_df[aspect_label] = pivot_train_df[aspect_label].astype(int)\n",
    "    \n",
    "    ood_train_df = []\n",
    "    for aspect_label in [\"ambiance_label\", \"food_label\", \"noise_label\", \"service_label\"]:\n",
    "\n",
    "        ood_0 = pivot_train_df[\n",
    "            (pivot_train_df[aspect_label]==1) &\n",
    "            (pivot_train_df[\"label\"]==0)\n",
    "        ]\n",
    "\n",
    "        ood_1 = pivot_train_df[\n",
    "            (pivot_train_df[aspect_label]==1) &\n",
    "            (pivot_train_df[\"label\"]==1)\n",
    "        ]\n",
    "\n",
    "        ood_3 = pivot_train_df[\n",
    "            (pivot_train_df[aspect_label]==0) &\n",
    "            (pivot_train_df[\"label\"]==3)\n",
    "        ]\n",
    "\n",
    "        ood_4 = pivot_train_df[\n",
    "            (pivot_train_df[aspect_label]==0) &\n",
    "            (pivot_train_df[\"label\"]==4)\n",
    "        ]\n",
    "\n",
    "        ood_train_df += [pd.concat(\n",
    "            (ood_0, ood_1, ood_3, ood_4)\n",
    "        )]\n",
    "    ood_train_df = pd.concat(ood_train_df).drop_duplicates()\n",
    "    \n",
    "    iid_train_df = pivot_train_df.iloc[\n",
    "        pivot_train_df.index.difference(\n",
    "            ood_train_df.index\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    return iid_train_df, ood_train_df, pivot_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "seed=7\n",
    "iid_train_df, ood_train_df, all_train_df = get_absa_labels_df(train_df)\n",
    "if k > 0:\n",
    "    if k >= len(ood_train_df):\n",
    "        k = len(ood_train_df)\n",
    "        k_shots_train = ood_train_df\n",
    "    else:\n",
    "        _, k_shots_train = train_test_split(\n",
    "            ood_train_df, test_size=k, random_state=seed\n",
    "        )\n",
    "    iid_train_df = pd.concat((\n",
    "        iid_train_df, \n",
    "        k_shots_train, \n",
    "    ))\n",
    "\n",
    "iid_dev_df, ood_dev_df, all_dev_df = get_absa_labels_df(\n",
    "    dev_df,\n",
    "    sequence_label_encode={\n",
    "        5: 4,\n",
    "        4: 3,\n",
    "        3: 2,\n",
    "        2: 1,\n",
    "        1: 0,\n",
    "    }\n",
    ")\n",
    "iid_test_df, ood_test_df, all_test_df = get_absa_labels_df(\n",
    "    test_df,\n",
    "    sequence_label_encode={\n",
    "        5: 4,\n",
    "        4: 3,\n",
    "        3: 2,\n",
    "        2: 1,\n",
    "        1: 0,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_df[\"food_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iid_train_df = Dataset.from_pandas(iid_train_df)\n",
    "\n",
    "all_dev_df = Dataset.from_pandas(all_dev_df)\n",
    "ood_dev_df = Dataset.from_pandas(ood_dev_df)\n",
    "iid_dev_df = Dataset.from_pandas(iid_dev_df)\n",
    "\n",
    "all_test_df = Dataset.from_pandas(all_test_df)\n",
    "ood_test_df = Dataset.from_pandas(ood_test_df)\n",
    "iid_test_df = Dataset.from_pandas(iid_test_df)\n",
    "\n",
    "opentable_seq_cls_dataset = DatasetDict()\n",
    "opentable_seq_cls_dataset['train'] = iid_train_df\n",
    "\n",
    "opentable_seq_cls_dataset['validation'] = all_dev_df\n",
    "opentable_seq_cls_dataset['validation_ood'] = ood_dev_df\n",
    "opentable_seq_cls_dataset['validation_iid'] = iid_dev_df\n",
    "\n",
    "opentable_seq_cls_dataset['test'] = all_test_df\n",
    "opentable_seq_cls_dataset['test_ood'] = ood_test_df\n",
    "opentable_seq_cls_dataset['test_iid'] = iid_test_df\n",
    "\n",
    "opentable_seq_cls_dataset.save_to_disk(f\"./datasets/sequence_classification_ood.k_{k}.seed_{seed}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opentable_seq_cls_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debiasing CPM with CEBaB\n",
    "Our Causal Proxy Model (CPM) has localized information about different concepts. The overall debiasing effort in CPM is letting the model to predict the output as if the concept that gets to be debiased is not presented in the text (i.e., the concept label is ``unknown``).\n",
    "\n",
    "In this document, we show that CPM can be integrated as a method to produce debiased model with respect to targeted concept. This document is just one example of how we can use CPM to produce debiased outputs. In the paper, we also discuss how the iCACE score relates to this debiased results.\n",
    "\n",
    "In this notebook, we will evaluate the following models:\n",
    "- CPM: `BERT-base-uncased`\n",
    "\n",
    "and we will evaluate with the following conditions:\n",
    "- 5-class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs import *\n",
    "from modelings.modelings_bert import *\n",
    "from modelings.modelings_roberta import *\n",
    "from modelings.modelings_gpt2 import *\n",
    "from modelings.modelings_lstm import *\n",
    "\n",
    "\"\"\"\n",
    "For evaluate, we use a single random seed, as\n",
    "the models are trained with 5 different seeds\n",
    "already.\n",
    "\"\"\"\n",
    "_ = random.seed(123)\n",
    "_ = np.random.seed(123)\n",
    "_ = torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The following blocks will run CEBaB benchmark in\n",
    "all the combinations of the following conditions.\n",
    "\"\"\"\n",
    "grid = {\n",
    "    \"eval_split\": [\"test\"],\n",
    "    # dev,test\n",
    "    \"control\": [\"ks\"],\n",
    "    # baseline-random,baseline-blackbox,hdims,layers,ks,approximate,ablation\n",
    "    \"seed\": [42],\n",
    "    # 42, 66, 77\n",
    "    \"h_dim\": [192],\n",
    "    # 1,16,64,128,192\n",
    "    # 1,16,64,75\n",
    "    \"interchange_layer\" : [10],\n",
    "    # 0,1; 2,4,6,8,10,12\n",
    "    \"class_num\": [5],\n",
    "    \"k\" : [19684], \n",
    "    # 0;10,100,500,1000,3000,6000,9848,19684\n",
    "    \"alpha\" : [1.0],\n",
    "    # 0.0,1.0\n",
    "    \"beta\" : [1.0],\n",
    "    # 0.0,1.0\n",
    "    \"gemma\" : [3.0],\n",
    "    # 0.0,3.0\n",
    "    \"model_arch\" : [\"bert-base-uncased\"],\n",
    "    # lstm, bert-base-uncased, roberta-base, gpt2\n",
    "    \"lr\" : [\"8e-05\"],\n",
    "    # 8e-05; 0.001\n",
    "    \"counterfactual_type\" : [\"true\"]\n",
    "    # approximate,true\n",
    "}\n",
    "\n",
    "keys, values = zip(*grid.items())\n",
    "permutations_dicts = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "device = 'cuda:9'\n",
    "batch_size = 32\n",
    "\n",
    "if grid[\"control\"][0] == \"hdims\" or grid[\"control\"][0] == \"layers\":\n",
    "    assert grid[\"eval_split\"][0] == \"dev\"\n",
    "else:\n",
    "    assert grid[\"eval_split\"][0] == \"test\"\n",
    "    \n",
    "aspect_label_encode = {\n",
    "    \"Negative\":0,\n",
    "    \"Positive\":1,\n",
    "    \"unknown\":2,\n",
    "    \"no majority\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "eval_split=permutations_dicts[i][\"eval_split\"]\n",
    "seed=permutations_dicts[i][\"seed\"]\n",
    "class_num=permutations_dicts[i][\"class_num\"]\n",
    "alpha=permutations_dicts[i][\"alpha\"]\n",
    "beta=permutations_dicts[i][\"beta\"]\n",
    "gemma=permutations_dicts[i][\"gemma\"]\n",
    "h_dim=permutations_dicts[i][\"h_dim\"]\n",
    "dataset_type = f'{class_num}-way'\n",
    "control=permutations_dicts[i][\"control\"]\n",
    "model_arch=permutations_dicts[i][\"model_arch\"]\n",
    "k=permutations_dicts[i][\"k\"]\n",
    "interchange_layer=permutations_dicts[i][\"interchange_layer\"]\n",
    "lr=permutations_dicts[i][\"lr\"]\n",
    "counterfactual_type=permutations_dicts[i][\"counterfactual_type\"]\n",
    "\n",
    "if model_arch == \"bert-base-uncased\":\n",
    "    model_path = \"BERT\"\n",
    "    model_module = BERTForCEBaB\n",
    "    explainer_module = CausalProxyModelForBERT\n",
    "elif model_arch == \"roberta-base\":\n",
    "    model_path = \"RoBERTa\" \n",
    "    model_module = RoBERTaForCEBaB\n",
    "    explainer_module = CausalProxyModelForRoBERTa\n",
    "elif model_arch == \"gpt2\":\n",
    "    model_path = \"gpt2\"\n",
    "    model_module = GPT2ForCEBaB\n",
    "    explainer_module = CausalProxyModelForGPT2\n",
    "elif model_arch == \"lstm\":\n",
    "    model_path = \"lstm\"\n",
    "    model_module = LSTMForCEBaB\n",
    "    explainer_module = CausalProxyModelForLSTM\n",
    "model_path += f\"-{control}\"\n",
    "grid_conditions=(\n",
    "    (\"eval_split\", eval_split),\n",
    "    (\"control\", control),\n",
    "    (\"seed\", seed),\n",
    "    (\"h_dim\", h_dim),\n",
    "    (\"interchange_layer\", interchange_layer),\n",
    "    (\"class_num\", class_num),\n",
    "    (\"k\", k),\n",
    "    (\"alpha\", alpha),\n",
    "    (\"beta\", beta),\n",
    "    (\"gemma\", gemma),\n",
    "    (\"model_arch\", model_arch),\n",
    "    (\"lr\", lr),\n",
    "    (\"counterfactual_type\", counterfactual_type)\n",
    ")\n",
    "print(\"Running for this setting: \", grid_conditions)\n",
    "\n",
    "blackbox_model_path = f'CEBaB/{model_arch}.CEBaB.sa.'\\\n",
    "                      f'{class_num}-class.exclusive.seed_{seed}'\n",
    "cpm_model_path = f'../proxy_training_results/{model_path}/'\\\n",
    "                 f'cebab.alpha.{alpha}.beta.{beta}.gemma.{gemma}.'\\\n",
    "                 f'lr.{lr}.dim.{h_dim}.hightype.{model_arch}.'\\\n",
    "                 f'CEBaB.cls.dropout.0.1.enc.dropout.0.1.counter.type.'\\\n",
    "                 f'{counterfactual_type}.k.{k}.int.layer.{interchange_layer}.'\\\n",
    "                 f'seed_{seed}/'\n",
    "\n",
    "# load data from HF\n",
    "cebab = datasets.load_dataset(\n",
    "    'CEBaB/CEBaB', use_auth_token=True,\n",
    "    cache_dir=\"../train_cache/\"\n",
    ")\n",
    "\n",
    "train, dev, test = preprocess_hf_dataset_inclusive(\n",
    "    cebab, verbose=1, dataset_type=dataset_type\n",
    ")\n",
    "\n",
    "eval_dataset = dev if eval_split == 'dev' else test\n",
    "\n",
    "tf_model = model_module(\n",
    "    blackbox_model_path, \n",
    "    device=device, \n",
    "    batch_size=batch_size\n",
    ")\n",
    "explainer = explainer_module(\n",
    "    blackbox_model_path,\n",
    "    cpm_model_path, \n",
    "    device=device, \n",
    "    batch_size=batch_size,\n",
    "    intervention_h_dim=h_dim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decorrelate_concept = \"service\" # TODO: integrate this, make it as a function!\n",
    "\n",
    "correlate_results = []\n",
    "decorrelate_results = []\n",
    "\n",
    "train_df = train[0]\n",
    "for index, row in eval_dataset.iterrows():\n",
    "    ambiance = row['ambiance_aspect_majority']\n",
    "    food = row['food_aspect_majority']\n",
    "    noise = row['noise_aspect_majority']\n",
    "    service = row['service_aspect_majority']\n",
    "    description = row['description']\n",
    "\n",
    "    # Original ratings.\n",
    "    x = explainer.tokenizer([description], padding=True, truncation=True, return_tensors='pt')\n",
    "    x_batch = {k: v.to(explainer.device) for k, v in x.items()}\n",
    "    outputs = explainer.blackbox_model(\n",
    "        **x_batch,\n",
    "    )\n",
    "    output_logit = torch.nn.functional.softmax(\n",
    "        outputs.logits.cpu(), dim=-1\n",
    "    ).detach()[0]\n",
    "    vp_class_prob = output_logit[-1].tolist()\n",
    "    correlate_results += [(ambiance, food, noise, service, vp_class_prob)]\n",
    "    \n",
    "    # sample a trainign as the counterfactual outputs!\n",
    "    satisfied_rows = train_df[\n",
    "        (train_df[f\"{decorrelate_concept}_aspect_majority\"]==\\\n",
    "         \"unknown\")\n",
    "    ]\n",
    "    sampled_source = satisfied_rows.sample(random_state=seed).iloc[0]\n",
    "    source_description = sampled_source['description']\n",
    "    source_x = explainer.tokenizer([source_description], padding=True, truncation=True, return_tensors='pt')\n",
    "    source_x_batch = {k: v.to(explainer.device) for k, v in source_x.items()}\n",
    "    \n",
    "    if decorrelate_concept == \"ambiance\":\n",
    "        intervention_type_batch = torch.tensor([0]).long().to(explainer.device)\n",
    "    if decorrelate_concept == \"food\":\n",
    "        intervention_type_batch = torch.tensor([1]).long().to(explainer.device)\n",
    "    if decorrelate_concept == \"noise\":\n",
    "        intervention_type_batch = torch.tensor([2]).long().to(explainer.device)\n",
    "    if decorrelate_concept == \"service\":\n",
    "        intervention_type_batch = torch.tensor([3]).long().to(explainer.device)\n",
    "    \n",
    "    base_input_ids = x_batch['input_ids']\n",
    "    base_attention_mask = x_batch['attention_mask']\n",
    "    source_input_ids = source_x_batch['input_ids']\n",
    "    source_attention_mask = source_x_batch['attention_mask']\n",
    "    \n",
    "    # Decorrelate ratings.\n",
    "    _, _, counterfactual_outputs = explainer.cpm_model.forward(\n",
    "        base=(base_input_ids, base_attention_mask),\n",
    "        source=(source_input_ids, source_attention_mask),\n",
    "        base_intervention_corr=intervention_type_batch,\n",
    "        source_intervention_corr=intervention_type_batch,\n",
    "    )\n",
    "    prediction_counterfactual_batch = torch.nn.functional.softmax(\n",
    "        counterfactual_outputs[\"logits\"][0].cpu(), dim=-1\n",
    "    ).detach()[0]\n",
    "\n",
    "    intervened_vp_class_prob = prediction_counterfactual_batch[-1].tolist()\n",
    "    decorrelate_results += [(ambiance, food, noise, service, intervened_vp_class_prob)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_logits(\n",
    "    correlate_results,\n",
    "    concept_idx,\n",
    "):\n",
    "    group_results = {\n",
    "        \"Negative\" : [],\n",
    "        \"unknown\" : [],\n",
    "        \"Positive\" : [],\n",
    "    }\n",
    "    for i in range(len(correlate_results)):\n",
    "        if correlate_results[i][concept_idx] != \"\":\n",
    "            logit = correlate_results[i][-1]\n",
    "            group_results[correlate_results[i][concept_idx]].append(logit)\n",
    "    return group_results\n",
    "\n",
    "def subplot_func(ax, index, results, with_labels=False, with_title=False):\n",
    "    group_result = group_logits(results, index)\n",
    "    names = [\"ambiance\", \"food\", \"noise\", \"service\"]\n",
    "    ax.boxplot(\n",
    "        np.asarray([\n",
    "            group_result[\"Negative\"],\n",
    "            group_result[\"unknown\"],\n",
    "            group_result[\"Positive\"],\n",
    "        ], dtype=object), \n",
    "        labels=[\"neg\", \"unk\", \"pos\"]\n",
    "    )\n",
    "    line_x = []\n",
    "    linx_y = []\n",
    "    for l in group_result[\"Negative\"]:\n",
    "        line_x.append(1)\n",
    "        linx_y.append(l)\n",
    "    for l in group_result[\"unknown\"]:\n",
    "        line_x.append(2)\n",
    "        linx_y.append(l)\n",
    "    for l in group_result[\"Positive\"]:\n",
    "        line_x.append(3)\n",
    "        linx_y.append(l)\n",
    "    corr, _ = pearsonr(line_x, linx_y)\n",
    "    corr = round(corr, 2)\n",
    "    ax.plot(\n",
    "        np.unique(line_x), np.poly1d(\n",
    "            np.polyfit(line_x, linx_y, 1)\n",
    "        )(np.unique(line_x)),\n",
    "        linestyle='dashdot',\n",
    "        color='red',\n",
    "        alpha=0.8,\n",
    "        linewidth=2,\n",
    "        label=f\"corr={corr}\"\n",
    "    )\n",
    "    ax.legend(\n",
    "        loc=\"upper right\",\n",
    "        ncol=1, fancybox=True, fontsize=15,\n",
    "        framealpha=0.2\n",
    "    )\n",
    "    if with_title:\n",
    "        ax.set_title(names[index], fontsize=20)\n",
    "    if not with_labels:\n",
    "        ax.get_xaxis().set_ticks([])\n",
    "    else:\n",
    "        ax.xaxis.set_tick_params(labelsize=20)\n",
    "\n",
    "    ax.set_facecolor(\"white\")\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context({'axes.edgecolor':'black', 'xtick.color':'black', 'ytick.color':'black', 'figure.facecolor':'white'}):\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(18, 4))\n",
    "    # Blackbox model\n",
    "    for i in range(0, 4):\n",
    "        subplot_func(axs[0,i], i, correlate_results, with_title=True)\n",
    "        axs[0,0].set_ylabel(\"Finetuned\", fontsize=20)\n",
    "        \n",
    "    # CPM\n",
    "    for i in range(0, 4):\n",
    "        subplot_func(axs[1,i], i, decorrelate_results, with_labels=True)\n",
    "        axs[1,0].set_ylabel(r'CPM$_{\\rm HI}$', fontsize=20)\n",
    "    plt.savefig(f\"./figures/debiasing-{decorrelate_concept}.png\",dpi=200, bbox_inches='tight')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset, DatasetDict, Features, Value\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    CONFIG_MAPPING,\n",
    "    MODEL_FOR_MASKED_LM_MAPPING,\n",
    "    AutoConfig,\n",
    "    AutoModelForMaskedLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from transformers.utils import check_min_version\n",
    "from transformers.utils.versions import require_version\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "from libs import *\n",
    "from modelings.modelings_bert import *\n",
    "from modelings.modelings_roberta import *\n",
    "from modelings.modelings_gpt2 import *\n",
    "from modelings.modelings_lstm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.logging.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "push model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The following blocks will run CEBaB benchmark in\n",
    "all the combinations of the following conditions.\n",
    "\"\"\"\n",
    "grid = {\n",
    "    \"eval_split\": [\"test\"],\n",
    "    # dev,test\n",
    "    \"control\": [\"ks\"],\n",
    "    # baseline-random,baseline-blackbox,hdims,layers,ks,approximate,ablation\n",
    "    \"seed\": [42, 66, 77],\n",
    "    # 42, 66, 77\n",
    "    \"h_dim\": [192],\n",
    "    # 1,16,64,128,192\n",
    "    # 1,16,64,75\n",
    "    \"interchange_layer\" : [10],\n",
    "    # 0,1; 2,4,6,8,10,12\n",
    "    \"class_num\": [5],\n",
    "    \"k\" : [19684], \n",
    "    # 0;10,100,500,1000,3000,6000,9848,19684\n",
    "    \"alpha\" : [1.0],\n",
    "    # 0.0,1.0\n",
    "    \"beta\" : [1.0],\n",
    "    # 0.0,1.0\n",
    "    \"gemma\" : [3.0],\n",
    "    # 0.0,3.0\n",
    "    \"model_arch\" : [\"bert-base-uncased\"],\n",
    "    # lstm, bert-base-uncased, roberta-base, gpt2\n",
    "    \"lr\" : [\"8e-05\"],\n",
    "    # 8e-05; 0.001\n",
    "    \"counterfactual_type\" : [\"true\"],\n",
    "    # approximate,true\n",
    "    \"random_source\" : [False]\n",
    "}\n",
    "\n",
    "keys, values = zip(*grid.items())\n",
    "permutations_dicts = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "device = 'cuda:1'\n",
    "batch_size = 32\n",
    "\n",
    "if grid[\"control\"][0] == \"hdims\" or grid[\"control\"][0] == \"layers\":\n",
    "    assert grid[\"eval_split\"][0] == \"dev\"\n",
    "else:\n",
    "    assert grid[\"eval_split\"][0] == \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(permutations_dicts)):\n",
    "    \n",
    "    eval_split=permutations_dicts[i][\"eval_split\"]\n",
    "    seed=permutations_dicts[i][\"seed\"]\n",
    "    class_num=permutations_dicts[i][\"class_num\"]\n",
    "    alpha=permutations_dicts[i][\"alpha\"]\n",
    "    beta=permutations_dicts[i][\"beta\"]\n",
    "    gemma=permutations_dicts[i][\"gemma\"]\n",
    "    h_dim=permutations_dicts[i][\"h_dim\"]\n",
    "    dataset_type = f'{class_num}-way'\n",
    "    control=permutations_dicts[i][\"control\"]\n",
    "    model_arch=permutations_dicts[i][\"model_arch\"]\n",
    "    k=permutations_dicts[i][\"k\"]\n",
    "    interchange_layer=permutations_dicts[i][\"interchange_layer\"]\n",
    "    lr=permutations_dicts[i][\"lr\"]\n",
    "    counterfactual_type=permutations_dicts[i][\"counterfactual_type\"]\n",
    "    random_source=permutations_dicts[i][\"random_source\"]\n",
    "    \n",
    "    if model_arch == \"bert-base-uncased\":\n",
    "        model_path = \"BERT\"\n",
    "        model_module = BERTForCEBaB\n",
    "        explainer_module = CausalProxyModelForBERT\n",
    "    elif model_arch == \"roberta-base\":\n",
    "        model_path = \"RoBERTa\" \n",
    "        model_module = RoBERTaForCEBaB\n",
    "        explainer_module = CausalProxyModelForRoBERTa\n",
    "    elif model_arch == \"gpt2\":\n",
    "        model_path = \"gpt2\"\n",
    "        model_module = GPT2ForCEBaB\n",
    "        explainer_module = CausalProxyModelForGPT2\n",
    "    elif model_arch == \"lstm\":\n",
    "        model_path = \"lstm\"\n",
    "        model_module = LSTMForCEBaB\n",
    "        explainer_module = CausalProxyModelForLSTM\n",
    "    model_path += f\"-{control}\"\n",
    "    grid_conditions=(\n",
    "        (\"eval_split\", eval_split),\n",
    "        (\"control\", control),\n",
    "        (\"seed\", seed),\n",
    "        (\"h_dim\", h_dim),\n",
    "        (\"interchange_layer\", interchange_layer),\n",
    "        (\"class_num\", class_num),\n",
    "        (\"k\", k),\n",
    "        (\"alpha\", alpha),\n",
    "        (\"beta\", beta),\n",
    "        (\"gemma\", gemma),\n",
    "        (\"model_arch\", model_arch),\n",
    "        (\"lr\", lr),\n",
    "        (\"counterfactual_type\", counterfactual_type)\n",
    "    )\n",
    "    print(\"Running for this setting: \", grid_conditions)\n",
    "\n",
    "    blackbox_model_path = f'CEBaB/{model_arch}.CEBaB.sa.'\\\n",
    "                          f'{class_num}-class.exclusive.seed_{seed}'\n",
    "    cpm_model_path = f'../proxy_training_results/{model_path}/'\\\n",
    "                     f'cebab.alpha.{alpha}.beta.{beta}.gemma.{gemma}.'\\\n",
    "                     f'lr.{lr}.dim.{h_dim}.hightype.{model_arch}.'\\\n",
    "                     f'CEBaB.cls.dropout.0.1.enc.dropout.0.1.counter.type.'\\\n",
    "                     f'{counterfactual_type}.k.{k}.int.layer.{interchange_layer}.'\\\n",
    "                     f'seed_{seed}/'\n",
    "    hub_name = f'cpm.{model_arch}.best.seed.{seed}'\n",
    "    explainer = explainer_module(\n",
    "        blackbox_model_path,\n",
    "        cpm_model_path, \n",
    "        device=device, \n",
    "        batch_size=batch_size,\n",
    "        intervention_h_dim=h_dim,\n",
    "        random_source=random_source\n",
    "    )\n",
    "    \n",
    "    explainer.cpm_model.model.push_to_hub(hub_name, organization=\"CPMs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

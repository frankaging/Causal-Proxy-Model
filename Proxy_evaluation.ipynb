{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This file loads the proxy model trained with IIT, and evaluate it for concept-based explanations with the CEBaB dataset.\n",
    "This file tends to follow the one in our OpenTable repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/cs.stanford.edu/u/wuzhengx/.local/lib/python3.7/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os \n",
    "import pandas as pd\n",
    "import datasets\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification, \n",
    "    AutoTokenizer, \n",
    "    AutoConfig,\n",
    ")\n",
    "from math import ceil\n",
    "\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from models.modelings_roberta import *\n",
    "from models.modelings_bert import *\n",
    "\n",
    "from eval_pipeline.models.abstract_model import Model \n",
    "from eval_pipeline.explainers.abstract_explainer import Explainer\n",
    "from eval_pipeline.utils.data_utils import preprocess_hf_dataset\n",
    "from eval_pipeline.customized_models.bert import BertForNonlinearSequenceClassification\n",
    "from eval_pipeline.utils import metric_utils, get_intervention_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb892065e30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: set random seeds.\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "def query_with_aspect_label(\n",
    "    df,\n",
    "    ambiance=\"Positive\",\n",
    "    service=\"Positive\",\n",
    "    noise=\"Positive\",\n",
    "    food=\"Positive\",\n",
    "):\n",
    "    return df[\n",
    "        (df[\"ambiance_aspect_majority\"]==ambiance)&\n",
    "        (df[\"service_aspect_majority\"]==service)&\n",
    "        (df[\"noise_aspect_majority\"]==noise)&\n",
    "        (df[\"food_aspect_majority\"]==food)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTForCEBaB(Model):\n",
    "    def __init__(self, model_path, device='cpu', batch_size=64):\n",
    "        self.device = device\n",
    "        self.model_path = model_path\n",
    "        self.tokenizer_path = model_path\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.model = BertForNonlinearSequenceClassification.from_pretrained(\n",
    "            self.model_path,\n",
    "            cache_dir=\"../huggingface_cache\"\n",
    "        )\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "        self.model.to(device)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.model_path.split('/')[-1]\n",
    "\n",
    "    def preprocess(self, df):\n",
    "        x = self.tokenizer(df['description'].to_list(), padding=True, truncation=True, return_tensors='pt')\n",
    "        y = df['review_majority'].astype(int)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def fit(self, dataset):\n",
    "        # assume model was already trained\n",
    "        pass\n",
    "\n",
    "    def predict_proba(self, dataset):\n",
    "        self.model.eval()\n",
    "\n",
    "        x, y = self.preprocess(dataset)\n",
    "\n",
    "        # get the predictions batch per batch\n",
    "        probas = []\n",
    "        for i in range(ceil(len(dataset) / self.batch_size)):\n",
    "            x_batch = {k: v[i * self.batch_size:(i + 1) * self.batch_size].to(self.device) for k, v in x.items()}\n",
    "            probas.append(torch.nn.functional.softmax(self.model(**x_batch).logits.cpu(), dim=-1).detach())\n",
    "\n",
    "        probas = torch.concat(probas)\n",
    "        probas = np.round(probas.numpy(), decimals=4)\n",
    "\n",
    "        predictions = np.argmax(probas, axis=1)\n",
    "        clf_report = classification_report(y.to_numpy(), predictions, output_dict=True)\n",
    "\n",
    "        return probas, clf_report\n",
    "\n",
    "    def get_embeddings(self, sentences_list):\n",
    "        x = self.tokenizer(sentences_list, padding=True, truncation=True, return_tensors='pt')\n",
    "        embeddings = []\n",
    "        for i in range(ceil(len(x['input_ids']) / self.batch_size)):\n",
    "            x_batch = {k: v[i * self.batch_size:(i + 1) * self.batch_size].to(self.device) for k, v in x.items()}\n",
    "            embeddings.append(self.model.base_model(**x_batch).pooler_output.detach().cpu().tolist())\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    def get_classification_head(self):\n",
    "        return self.model.classifier\n",
    "    \n",
    "def get_iit_examples(df):\n",
    "    \"\"\"\n",
    "    Given a dataframe in the new data scheme, return all intervention pairs.\n",
    "    \"\"\"\n",
    "    # Drop label distribution and worker information.\n",
    "    columns_to_keep = ['id', 'original_id', 'edit_id', 'is_original', 'edit_goal', 'edit_type', 'description', 'review_majority','food_aspect_majority', 'ambiance_aspect_majority', 'service_aspect_majority', 'noise_aspect_majority']\n",
    "    columns_to_keep += [col for col in df.columns if 'prediction' in col]\n",
    "    df = df[columns_to_keep]\n",
    "    return df\n",
    "\n",
    "class CausalProxyModel(Explainer):\n",
    "    def __init__(\n",
    "        self, \n",
    "        blackbox_model_path,\n",
    "        cpm_model_path, \n",
    "        device, batch_size, \n",
    "        intervention_h_dim=1,\n",
    "        min_iit_pair_examples=1,\n",
    "        match_non_int_type=True,\n",
    "    ):\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.min_iit_pair_examples = min_iit_pair_examples\n",
    "        self.match_non_int_type = match_non_int_type\n",
    "        # blackbox model loading.\n",
    "        self.blackbox_model = BertForNonlinearSequenceClassification.from_pretrained(\n",
    "            blackbox_model_path,\n",
    "            cache_dir=\"../huggingface_cache\"\n",
    "        )\n",
    "        self.blackbox_model.to(device)\n",
    "        \n",
    "        # causal proxy model loading.\n",
    "        cpm_config = AutoConfig.from_pretrained(\n",
    "            cpm_model_path,\n",
    "            cache_dir=\"../huggingface_cache/\",\n",
    "            use_auth_token=True if \"CEBaB/\" in model_path else False,\n",
    "        )\n",
    "        try:\n",
    "            cpm_config.intervention_h_dim = cpm_config.intervention_h_dim\n",
    "        except:\n",
    "            cpm_config.intervention_h_dim = intervention_h_dim\n",
    "        cpm_model = IITBERTForSequenceClassification.from_pretrained(\n",
    "            cpm_model_path,\n",
    "            config=cpm_config,\n",
    "            cache_dir=\"../huggingface_cache/\"\n",
    "        )\n",
    "        cpm_model.to(device)\n",
    "        self.cpm_model = InterventionableIITTransformerForSequenceClassification(\n",
    "            model=cpm_model\n",
    "        )\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        \n",
    "    def fit(self, dataset, classifier_predictions, classifier, dev_dataset=None):\n",
    "        # we don't need to train IIT here.\n",
    "        pass\n",
    "    \n",
    "    def preprocess(self, pairs_dataset, dev_dataset):\n",
    "        \n",
    "        # configs\n",
    "        min_iit_pair_examples = self.min_iit_pair_examples\n",
    "        match_non_int_type = self.match_non_int_type\n",
    "        \n",
    "        query_dataset = get_iit_examples(dev_dataset)\n",
    "        iit_pairs_dataset = []\n",
    "        iit_id = 0\n",
    "        for index, row in pairs_dataset.iterrows():\n",
    "            query_description_base = row['description_base']\n",
    "            query_int_type = row['intervention_type']\n",
    "            query_non_int_type = {\n",
    "                \"ambiance\", \"food\", \"noise\", \"service\"\n",
    "            } - {query_int_type}\n",
    "            query_int_aspect_base = row[\"intervention_aspect_base\"]\n",
    "            query_int_aspect_assignment = row['intervention_aspect_counterfactual']\n",
    "            query_original_id = row[\"original_id_base\"]\n",
    "            matched_iit_examples = query_dataset[\n",
    "                (query_dataset[f\"{query_int_type}_aspect_majority\"]==query_int_aspect_assignment)&\n",
    "                (query_dataset[\"original_id\"]!=query_original_id)\n",
    "            ]\n",
    "            if match_non_int_type:\n",
    "                for _t in query_non_int_type:\n",
    "                    matched_iit_examples = matched_iit_examples[\n",
    "                        (matched_iit_examples[f\"{_t}_aspect_majority\"]==\\\n",
    "                         row[f\"{_t}_aspect_majority_base\"])\n",
    "                    ]\n",
    "            if len(set(matched_iit_examples[\"id\"])) < min_iit_pair_examples:\n",
    "                if match_non_int_type:\n",
    "                    # simply avoid mapping the rest of the aspects.\n",
    "                    matched_iit_examples = query_dataset[\n",
    "                        (query_dataset[f\"{query_int_type}_aspect_majority\"]==query_int_aspect_assignment)&\n",
    "                        (query_dataset[\"original_id\"]!=query_original_id)\n",
    "                    ]\n",
    "                else:\n",
    "                    assert False # we need to check the number!\n",
    "            sampled_iit_example_ids = random.sample(\n",
    "                set(matched_iit_examples[\"id\"]), min_iit_pair_examples\n",
    "            )\n",
    "            for _id in sampled_iit_example_ids:\n",
    "                description_iit = query_dataset[query_dataset[\"id\"]==_id][\"description\"].iloc[0]\n",
    "                iit_pairs_dataset += [[\n",
    "                    iit_id,\n",
    "                    query_int_type,\n",
    "                    query_description_base, \n",
    "                    description_iit\n",
    "                ]]\n",
    "            iit_id += 1\n",
    "        iit_pairs_dataset = pd.DataFrame(\n",
    "            columns=[\n",
    "                'iit_id',\n",
    "                'intervention_type', \n",
    "                'description_base', \n",
    "                'description_iit'], \n",
    "            data=iit_pairs_dataset\n",
    "        )\n",
    "        \n",
    "        base_x = self.tokenizer(\n",
    "            iit_pairs_dataset['description_base'].to_list(), \n",
    "            padding=True, truncation=True, return_tensors='pt'\n",
    "        )\n",
    "        source_x = self.tokenizer(\n",
    "            iit_pairs_dataset['description_iit'].to_list(), \n",
    "            padding=True, truncation=True, return_tensors='pt'\n",
    "        )\n",
    "        intervention_corr = []\n",
    "        for _type in iit_pairs_dataset[\"intervention_type\"].tolist():\n",
    "            if _type == \"ambiance\":\n",
    "                intervention_corr += [0]\n",
    "            if _type == \"food\":\n",
    "                intervention_corr += [1]\n",
    "            if _type == \"noise\":\n",
    "                intervention_corr += [2]\n",
    "            if _type == \"service\":\n",
    "                intervention_corr += [3]\n",
    "        intervention_corr = torch.tensor(intervention_corr).long()\n",
    "        return base_x, source_x, intervention_corr, iit_pairs_dataset\n",
    "    \n",
    "    def estimate_icace(self, pairs, df):\n",
    "        CPM_iTEs = []\n",
    "        self.blackbox_model.eval()\n",
    "        self.cpm_model.model.eval()\n",
    "        base_x, source_x, intervention_corr, iit_pairs_dataset = self.preprocess(\n",
    "            pairs, df\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            for i in tqdm(range(ceil(len(iit_pairs_dataset)/self.batch_size))):\n",
    "                base_x_batch = {k:v[i*self.batch_size:(i+1)*self.batch_size].to(self.device) for k,v in base_x.items()} \n",
    "                source_x_batch = {k:v[i*self.batch_size:(i+1)*self.batch_size].to(self.device) for k,v in source_x.items()} \n",
    "                intervention_corr_batch = intervention_corr[i*self.batch_size:(i+1)*self.batch_size].to(self.device)\n",
    "                \n",
    "                base_outputs = torch.nn.functional.softmax(\n",
    "                    self.blackbox_model(**base_x_batch).logits.cpu(), dim=-1\n",
    "                ).detach()\n",
    "                _, _, counterfactual_outputs = self.cpm_model.forward(\n",
    "                    base=(base_x_batch['input_ids'], base_x_batch['attention_mask']),\n",
    "                    source=(source_x_batch['input_ids'], source_x_batch['attention_mask']),\n",
    "                    base_intervention_corr=intervention_corr_batch,\n",
    "                    source_intervention_corr=intervention_corr_batch,\n",
    "                )\n",
    "                counterfactual_outputs = torch.nn.functional.softmax(\n",
    "                    counterfactual_outputs[\"logits\"][0].cpu(), dim=-1\n",
    "                ).detach()\n",
    "                CPM_iTE = counterfactual_outputs-base_outputs\n",
    "                CPM_iTEs.append(CPM_iTE)\n",
    "        CPM_iTEs = torch.concat(CPM_iTEs)\n",
    "        CPM_iTEs = np.round(CPM_iTEs.numpy(), decimals=4)\n",
    "\n",
    "        # only for iit explainer!\n",
    "        iit_pairs_dataset[\"EiCaCE\"] = list(CPM_iTEs)\n",
    "        CPM_iTEs = list(iit_pairs_dataset.groupby([\"iit_id\"])[\"EiCaCE\"].mean())\n",
    "        \n",
    "        return CPM_iTEs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cebab_pipeline(\n",
    "    model, explainer, \n",
    "    train_dataset, dev_dataset, \n",
    "    dataset_type='5-way', \n",
    "    shorten_model_name=False\n",
    "):\n",
    "    # get predictions on train and dev\n",
    "    train_predictions, _ = model.predict_proba(\n",
    "        train_dataset\n",
    "    )\n",
    "    dev_predictions, dev_report = model.predict_proba(\n",
    "        dev_dataset\n",
    "    )\n",
    "\n",
    "    # append predictions to datasets\n",
    "    train_dataset['prediction'] = list(train_predictions)\n",
    "    dev_dataset['prediction'] = list(dev_predictions)\n",
    "\n",
    "    # fit explainer\n",
    "    explainer.fit(\n",
    "        train_dataset, train_predictions, \n",
    "        model, dev_dataset\n",
    "    )\n",
    "\n",
    "    # get intervention pairs\n",
    "    pairs_dataset = get_intervention_pairs(\n",
    "        dev_dataset, dataset_type=dataset_type\n",
    "    )  # TODO why is the index not unique here?\n",
    "        \n",
    "    # get explanations\n",
    "    explanations = explainer.estimate_icace(\n",
    "        pairs_dataset,\n",
    "        train_dataset\n",
    "    )\n",
    "    \n",
    "    # append explanations to the pairs\n",
    "    pairs_dataset['EICaCE'] = explanations\n",
    "    # TODO: add cosine\n",
    "    pairs_dataset = metric_utils._calculate_ite(pairs_dataset)  # effect of crowd-workers on other crowd-workers (no model, no explainer)\n",
    "    pairs_dataset = metric_utils._calculate_icace(pairs_dataset)  # effect of concept on the model (with model, no explainer)\n",
    "    pairs_dataset = metric_utils._calculate_estimate_loss(pairs_dataset)  # l2 CEBaB Score (model and explainer)\n",
    "\n",
    "    # only keep columns relevant for metrics\n",
    "    CEBaB_metrics_per_pair = pairs_dataset[[\n",
    "        'intervention_type', 'intervention_aspect_base', 'intervention_aspect_counterfactual', 'ITE', 'ICaCE', 'EICaCE', 'ICaCE-L2', 'ICaCE-cosine', 'ICaCE-normdiff']].copy()\n",
    "    CEBaB_metrics_per_pair['count'] = 1\n",
    "\n",
    "    # get CEBaB tables\n",
    "    metrics = ['count', 'ICaCE', 'EICaCE']\n",
    "\n",
    "    groupby_aspect_direction = ['intervention_type', 'intervention_aspect_base', 'intervention_aspect_counterfactual']\n",
    "\n",
    "    CaCE_per_aspect_direction = metric_utils._aggregate_metrics(CEBaB_metrics_per_pair, groupby_aspect_direction, metrics)\n",
    "    CaCE_per_aspect_direction.columns = ['count', 'CaCE', 'ECaCE']\n",
    "    CaCE_per_aspect_direction = CaCE_per_aspect_direction.set_index(['count'], append=True)\n",
    "    \n",
    "    ACaCE_per_aspect = metric_utils._aggregate_metrics(CaCE_per_aspect_direction.abs(), ['intervention_type'], ['CaCE', 'ECaCE'])\n",
    "    ACaCE_per_aspect.columns = ['ACaCE', 'EACaCE']\n",
    "\n",
    "    CEBaB_metrics_per_aspect_direction = metric_utils._aggregate_metrics(CEBaB_metrics_per_pair, groupby_aspect_direction, ['count', 'ICaCE-L2', 'ICaCE-cosine', 'ICaCE-normdiff'])\n",
    "    CEBaB_metrics_per_aspect_direction.columns = ['count', 'ICaCE-L2', 'ICaCE-cosine', 'ICaCE-normdiff']\n",
    "    CEBaB_metrics_per_aspect_direction = CEBaB_metrics_per_aspect_direction.set_index(['count'], append=True)\n",
    "\n",
    "    CEBaB_metrics_per_aspect = metric_utils._aggregate_metrics(CEBaB_metrics_per_pair, ['intervention_type'], ['count', 'ICaCE-L2', 'ICaCE-cosine', 'ICaCE-normdiff'])\n",
    "    CEBaB_metrics_per_aspect.columns = ['count', 'ICaCE-L2', 'ICaCE-cosine', 'ICaCE-normdiff']\n",
    "    CEBaB_metrics_per_aspect = CEBaB_metrics_per_aspect.set_index(['count'], append=True)\n",
    "\n",
    "    CEBaB_metrics = metric_utils._aggregate_metrics(CEBaB_metrics_per_pair, [], ['ICaCE-L2', 'ICaCE-cosine', 'ICaCE-normdiff'])\n",
    "\n",
    "    # get ATE table\n",
    "    ATE = metric_utils._aggregate_metrics(CEBaB_metrics_per_pair, groupby_aspect_direction, ['count', 'ITE'])\n",
    "    ATE.columns = ['count', 'ATE']\n",
    "\n",
    "    # add model and explainer information\n",
    "    if shorten_model_name:\n",
    "        model_name = str(model).split('.')[0]\n",
    "    else:\n",
    "        model_name = str(model)\n",
    "\n",
    "    CaCE_per_aspect_direction.columns = pd.MultiIndex.from_tuples(\n",
    "        [(model_name, str(explainer), col) if col != 'CaCE' else (model_name, '', col) for col in CaCE_per_aspect_direction.columns])\n",
    "    ACaCE_per_aspect.columns = pd.MultiIndex.from_tuples(\n",
    "        [(model_name, str(explainer), col) if col != 'ACaCE' else (model_name, '', col) for col in ACaCE_per_aspect.columns])\n",
    "    CEBaB_metrics_per_aspect_direction.columns = pd.MultiIndex.from_tuples(\n",
    "        [(model_name, str(explainer), col) for col in CEBaB_metrics_per_aspect_direction.columns])\n",
    "    CEBaB_metrics_per_aspect.columns = pd.MultiIndex.from_tuples(\n",
    "        [(model_name, str(explainer), col) for col in CEBaB_metrics_per_aspect.columns])\n",
    "    CEBaB_metrics.index = pd.MultiIndex.from_product([[model_name], [str(explainer)], CEBaB_metrics.index])\n",
    "    \n",
    "    # performance report\n",
    "    performance_report_index = ['macro-f1', 'accuracy']\n",
    "    performance_report_data = [dev_report['macro avg']['f1-score'], dev_report['accuracy']]\n",
    "    performance_report_col = [model_name]\n",
    "    performance_report = pd.DataFrame(data=performance_report_data, index=performance_report_index, columns=performance_report_col)\n",
    "\n",
    "    return ATE, CEBaB_metrics, CEBaB_metrics_per_aspect_direction, CEBaB_metrics_per_aspect, CaCE_per_aspect_direction, ACaCE_per_aspect, performance_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration CEBaB--CEBaB-0e2f7ed67c9d7e55\n",
      "Reusing dataset parquet (../huggingface_cache/parquet/CEBaB--CEBaB-0e2f7ed67c9d7e55/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc869761aa7c41188f94a7c4c923a360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping no majority reviews: 16.03% of train dataset.\n",
      "Dropped 2604 examples with a neutral label.\n",
      "Dropped 452 examples with a neutral label.\n",
      "Dropped 461 examples with a neutral label.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dfs/user/wuzhengx/workspace/causal-proxy-model/eval_pipeline/utils/data_utils.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['review_majority'] = dataset['review_majority'].apply(lambda score: encoding[score])\n"
     ]
    }
   ],
   "source": [
    "seed=42\n",
    "blackbox_model_path = f'CEBaB/bert-base-uncased.CEBaB.sa.2-class.exclusive.seed_{seed}'\n",
    "cpm_model_path = f'./proxy_training_results/'\\\n",
    "                   f'cebab.train.train.alpha.1.0'\\\n",
    "                   f'.beta.1.0.gemma.3.0.dim.128.hightype.'\\\n",
    "                   f'bert-base-uncased.Proxy.'\\\n",
    "                   f'CEBaB.sa.2-class.exclusive.'\\\n",
    "                   f'mode.align.seed_{seed}'\n",
    "# proxy_model_path = model_path\n",
    "\n",
    "dataset_type = '2-way'\n",
    "device = 'cuda:6'\n",
    "batch_size = 32\n",
    "\n",
    "# load data from HF\n",
    "cebab = datasets.load_dataset(\n",
    "    'CEBaB/CEBaB', use_auth_token=True,\n",
    "    cache_dir=\"../huggingface_cache/\"\n",
    ")\n",
    "cebab['train'] = cebab['train_exclusive']\n",
    "train, dev, test = preprocess_hf_dataset(\n",
    "    cebab, one_example_per_world=False, \n",
    "    verbose=1, dataset_type=dataset_type\n",
    ")\n",
    "\n",
    "tf_model = BERTForCEBaB(\n",
    "    blackbox_model_path, \n",
    "    device=device, \n",
    "    batch_size=batch_size\n",
    ")\n",
    "explanator = CausalProxyModel(\n",
    "    blackbox_model_path,\n",
    "    cpm_model_path, \n",
    "    device=device, \n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "train_dataset = train.copy()\n",
    "dev_dataset = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:13<00:00,  5.26it/s]\n"
     ]
    }
   ],
   "source": [
    "ATE, CEBaB_metrics, CEBaB_metrics_per_aspect_direction, \\\n",
    "CEBaB_metrics_per_aspect, CaCE_per_aspect_direction, \\\n",
    "ACaCE_per_aspect, performance_report = cebab_pipeline(\n",
    "    tf_model, explanator, \n",
    "    train_dataset, dev_dataset, \n",
    "    dataset_type='2-way'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bert-base-uncased.CEBaB.sa.2-class.exclusive.seed_42</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro-f1</th>\n",
       "      <td>0.976104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.976384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bert-base-uncased.CEBaB.sa.2-class.exclusive.seed_42\n",
       "macro-f1                                           0.976104   \n",
       "accuracy                                           0.976384   "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ICaCE-L2</th>\n",
       "      <th>ICaCE-cosine</th>\n",
       "      <th>ICaCE-normdiff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bert-base-uncased.CEBaB.sa.2-class.exclusive.seed_42</th>\n",
       "      <th>CausalProxyModel</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.2032</td>\n",
       "      <td>0.7881</td>\n",
       "      <td>0.202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          ICaCE-L2  \\\n",
       "bert-base-uncased.CEBaB.sa.2-class.exclusive.se... CausalProxyModel mean    0.2032   \n",
       "\n",
       "                                                                          ICaCE-cosine  \\\n",
       "bert-base-uncased.CEBaB.sa.2-class.exclusive.se... CausalProxyModel mean        0.7881   \n",
       "\n",
       "                                                                          ICaCE-normdiff  \n",
       "bert-base-uncased.CEBaB.sa.2-class.exclusive.se... CausalProxyModel mean           0.202  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CEBaB_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">bert-base-uncased.CEBaB.sa.2-class.exclusive.seed_42</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">CausalProxyModel</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ICaCE-L2</th>\n",
       "      <th>ICaCE-cosine</th>\n",
       "      <th>ICaCE-normdiff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intervention_type</th>\n",
       "      <th>count</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ambiance</th>\n",
       "      <th>504</th>\n",
       "      <td>0.1570</td>\n",
       "      <td>0.9008</td>\n",
       "      <td>0.1541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <th>696</th>\n",
       "      <td>0.2838</td>\n",
       "      <td>0.5417</td>\n",
       "      <td>0.2823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noise</th>\n",
       "      <th>470</th>\n",
       "      <td>0.0921</td>\n",
       "      <td>0.9532</td>\n",
       "      <td>0.0919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service</th>\n",
       "      <th>624</th>\n",
       "      <td>0.2343</td>\n",
       "      <td>0.8478</td>\n",
       "      <td>0.2341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        bert-base-uncased.CEBaB.sa.2-class.exclusive.seed_42  \\\n",
       "                                                            CausalProxyModel   \n",
       "                                                                    ICaCE-L2   \n",
       "intervention_type count                                                        \n",
       "ambiance          504                                               0.1570     \n",
       "food              696                                               0.2838     \n",
       "noise             470                                               0.0921     \n",
       "service           624                                               0.2343     \n",
       "\n",
       "                                                     \n",
       "                                                     \n",
       "                        ICaCE-cosine ICaCE-normdiff  \n",
       "intervention_type count                              \n",
       "ambiance          504         0.9008         0.1541  \n",
       "food              696         0.5417         0.2823  \n",
       "noise             470         0.9532         0.0919  \n",
       "service           624         0.8478         0.2341  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CEBaB_metrics_per_aspect"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
